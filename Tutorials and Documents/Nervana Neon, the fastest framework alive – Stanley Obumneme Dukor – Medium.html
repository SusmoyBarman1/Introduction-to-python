<!DOCTYPE html><html xmlns:cc="http://creativecommons.org/ns#"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=contain"><title>Nervana Neon, the fastest framework alive – Stanley Obumneme Dukor – Medium</title><link rel="canonical" href="https://medium.com/@stanleydukor/nervana-neon-the-fastest-framework-alive-e449d3e2a20d"><meta name="title" content="Nervana Neon, the fastest framework alive – Stanley Obumneme Dukor – Medium"><meta name="referrer" content="unsafe-url"><meta name="description" content="After presentations from The Torch Panther (Team PyTorch), The Tensors (Team Tensor flow), The Ancestral Intelligence (Team Theano) and The Karessing (Team Keras). We decided to show off the power of…"><meta name="theme-color" content="#000000"><meta property="og:title" content="Nervana Neon, the fastest framework alive – Stanley Obumneme Dukor – Medium"><meta property="twitter:title" content="Nervana Neon, the fastest framework alive – Stanley Obumneme Dukor – Medium"><meta property="og:url" content="https://medium.com/@stanleydukor/nervana-neon-the-fastest-framework-alive-e449d3e2a20d"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1200/1*dw1eUeQAY6soxr-rO3BlGA.jpeg"><meta property="fb:app_id" content="542599432471018"><meta property="og:description" content="INTRODUCTION"><meta name="twitter:description" content="INTRODUCTION"><meta name="twitter:image:src" content="https://cdn-images-1.medium.com/max/1200/1*dw1eUeQAY6soxr-rO3BlGA.jpeg"><link rel="publisher" href="https://plus.google.com/103654360130207659246"><link rel="author" href="https://medium.com/@stanleydukor"><meta property="author" content="Stanley Obumneme Dukor"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta property="article:publisher" content="https://www.facebook.com/medium"><meta property="article:author" content="https://medium.com/@stanleydukor"><meta name="robots" content="index, follow"><meta property="article:published_time" content="2018-04-06T04:17:08.148Z"><meta name="twitter:creator" content="@stanleydukor"><meta name="twitter:site" content="@Medium"><meta property="og:site_name" content="Medium"><meta name="twitter:label1" value="Reading time"><meta name="twitter:data1" value="10 min read"><meta name="twitter:app:name:iphone" content="Medium"><meta name="twitter:app:id:iphone" content="828256236"><meta name="twitter:app:url:iphone" content="medium://p/e449d3e2a20d"><meta property="al:ios:app_name" content="Medium"><meta property="al:ios:app_store_id" content="828256236"><meta property="al:android:package" content="com.medium.reader"><meta property="al:android:app_name" content="Medium"><meta property="al:ios:url" content="medium://p/e449d3e2a20d"><meta property="al:android:url" content="medium://p/e449d3e2a20d"><meta property="al:web:url" content="https://medium.com/@stanleydukor/nervana-neon-the-fastest-framework-alive-e449d3e2a20d"><link rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml" /><link rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/e449d3e2a20d" /><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","image":{"@type":"ImageObject","width":1920,"height":1440,"url":"https://cdn-images-1.medium.com/max/2000/1*dw1eUeQAY6soxr-rO3BlGA.jpeg"},"url":"https://medium.com/@stanleydukor/nervana-neon-the-fastest-framework-alive-e449d3e2a20d","dateCreated":"2018-04-06T04:17:08.148Z","datePublished":"2018-04-06T04:17:08.148Z","dateModified":"2018-04-22T23:57:35.700Z","headline":"Nervana Neon, the fastest framework alive","name":"Nervana Neon, the fastest framework alive","thumbnailUrl":"https://cdn-images-1.medium.com/max/2000/1*dw1eUeQAY6soxr-rO3BlGA.jpeg","keywords":["Tag:Machine Learning","Tag:Deep Learning","Tag:Artificial Intelligence","Tag:Artificial Neural Network","Tag:Convolutional Network","LockedPostSource:0","Elevated:false","LayerCake:0"],"author":{"@type":"Person","name":"Stanley Obumneme Dukor","url":"https://medium.com/@stanleydukor"},"creator":["Stanley Obumneme Dukor"],"publisher":{"@type":"Organization","name":"Medium","url":"https://medium.com/","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https://cdn-images-1.medium.com/max/385/1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https://medium.com/@stanleydukor/nervana-neon-the-fastest-framework-alive-e449d3e2a20d"}</script><meta name="parsely-link" content="https://medium.com/@stanleydukor/nervana-neon-the-fastest-framework-alive-e449d3e2a20d"><link rel="stylesheet" type="text/css" class="js-glyph-" id="glyph-8" href="https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css" /><link rel="stylesheet" href="https://cdn-static-1.medium.com/_/fp/css/main-branding-base.DY6Dh0-zrN6nkMSZtjrqgA.css"><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener("error", _onerror, true); else if (document.attachEvent) document.attachEvent("onerror", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("script"); s.type = "text/javascript"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("link"); s.rel = "stylesheet"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = "/_/stat?event=pixel.load&origin=" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga("create", "UA-24232453-2", "auto", {"allowLinker": true, "legacyCookieDomain": window.location.hostname}); ga("send", "pageview");</script><script async src="https://www.google-analytics.com/analytics.js"></script><!--[if lt IE 9]><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js"></script><![endif]--><link rel="icon" href="https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico" class="js-favicon"><link rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/190/190/1*8I-HPL0bfoIzGied-dzOvA.png"><link rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/150/150/1*8I-HPL0bfoIzGied-dzOvA.png"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/95/95/1*8I-HPL0bfoIzGied-dzOvA.png"><link rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/75/75/1*8I-HPL0bfoIzGied-dzOvA.png"><link rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"></head><body itemscope class=" postShowScreen browser-firefox os-windows is-withMagicUnderlinesv-glyph v-glyph--m2 is-noJs"><script>document.body.className = document.body.className.replace(/(^|\s)is-noJs(\s|$)/, "$1is-js$2")</script><div class="site-main" id="container"><div class="butterBar butterBar--error"></div><div class="surface"><div id="prerendered" class="screenContent"><canvas class="canvas-renderer"></canvas><div class="container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer"></div><div class="metabar u-clearfix js-metabar u-boxShadow4px12pxBlackLightest"><div class="branch-journeys-top"></div><div class="js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1032 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingHorizontal20"><div class="metabar-block u-flex1 u-flexCenter"><div class="u-xs-hide js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-flex0 u-flexCenter u-paddingTop0 u-fillTransparentBlackDarker"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0 u-fillTransparentBlackDarker"><svg class="svgIcon-use" width="45" height="45" ><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"/></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-xs-show js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-flex0 u-flexCenter u-paddingTop0 u-fillTransparentBlackDarker"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0 u-fillTransparentBlackDarker"><svg class="svgIcon-use" width="45" height="45" ><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"/></svg></span><span class="u-textScreenReader">Homepage</span></a></div></div><div class="metabar-block u-flex0"><div class="buttonSet buttonSet--wide"><label class="button button--small button--chromeless button--withIcon button--withSvgIcon inputGroup u-sm-hide metabar-predictiveSearch u-baseColor--buttonNormal u-baseColor--placeholderNormal" title="Search Medium"><span class="svgIcon svgIcon--search svgIcon--25px u-baseColor--iconLight"><svg class="svgIcon-use" width="25" height="25" ><path d="M20.067 18.933l-4.157-4.157a6 6 0 1 0-.884.884l4.157 4.157a.624.624 0 1 0 .884-.884zM6.5 11c0-2.62 2.13-4.75 4.75-4.75S16 8.38 16 11s-2.13 4.75-4.75 4.75S6.5 13.62 6.5 11z"/></svg></span><input class="js-predictiveSearchInput textInput textInput--rounded textInput--darkText u-baseColor--textNormal textInput--transparent" type="search" placeholder="Search Medium" required="true" /></label><a class="button button--small button--chromeless u-sm-show is-inSiteNavBar u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-xs-top1"   href="https://medium.com/search" title="Search" aria-label="Search"><span class="button-defaultState"><span class="svgIcon svgIcon--search svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" ><path d="M20.067 18.933l-4.157-4.157a6 6 0 1 0-.884.884l4.157 4.157a.624.624 0 1 0 .884-.884zM6.5 11c0-2.62 2.13-4.75 4.75-4.75S16 8.38 16 11s-2.13 4.75-4.75 4.75S6.5 13.62 6.5 11z"/></svg></span></span></a><button class="button button--small button--chromeless is-inSiteNavBar u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--activity js-notificationsButton u-marginRight16 u-xs-marginRight10 u-lineHeight0 u-size25x25"  title="Notifications" aria-label="Notifications" data-action="open-notifications"><span class="svgIcon svgIcon--bell svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"  viewBox="-293 409 25 25"><path d="M-273.327 423.67l-1.673-1.52v-3.646a5.5 5.5 0 0 0-6.04-5.474c-2.86.273-4.96 2.838-4.96 5.71v3.41l-1.68 1.553c-.204.19-.32.456-.32.734V427a1 1 0 0 0 1 1h3.49a3.079 3.079 0 0 0 3.01 2.45 3.08 3.08 0 0 0 3.01-2.45h3.49a1 1 0 0 0 1-1v-2.59c0-.28-.12-.55-.327-.74zm-7.173 5.63c-.842 0-1.55-.546-1.812-1.3h3.624a1.92 1.92 0 0 1-1.812 1.3zm6.35-2.45h-12.7v-2.347l1.63-1.51c.236-.216.37-.522.37-.843v-3.41c0-2.35 1.72-4.356 3.92-4.565a4.353 4.353 0 0 1 4.78 4.33v3.645c0 .324.137.633.376.85l1.624 1.477v2.373z"/></svg></span></button><a class="button button--small button--upsellNav button--withChrome u-baseColor--buttonNormal u-xs-hide js-upgradeMembershipAction"   href="https://medium.com/membership?source=upgrade_membership---nav_full" data-disable-client-nav="true">Upgrade</a><button class="button button--chromeless u-baseColor--buttonNormal is-inSiteNavBar js-userActions"  aria-haspopup="true" data-action="open-userActions"><div class="avatar"><img  src="https://cdn-images-1.medium.com/fit/c/40/40/0*Mibd2O6zN4HuKWZT" class="avatar-image avatar-image--icon" alt="Susmoy Barman"></div></button></div></div></div></div><div class="metabar metabar--spacer js-metabarSpacer u-height65 u-xs-height56"></div><main role="main"><article class=" u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full"  lang="en"><header class="container u-maxWidth740"><div class="uiScale uiScale-ui--regular uiScale-caption--regular u-paddingBottom10 row postMetaHeader"><div class="col u-size12of12 js-postMetaLockup"><div class="uiScale uiScale-ui--regular uiScale-caption--regular postMetaLockup postMetaLockup--authorLockupForPost u-flexCenter js-postMetaLockup"><div class="u-flex0"><a class="link u-baseColor--link avatar"   href="https://medium.com/@stanleydukor?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="3f0ab8856359" data-action-type="hover" data-user-id="3f0ab8856359" dir="auto"><img  src="https://cdn-images-1.medium.com/fit/c/75/75/1*r_QtBzZxwh6x-0BPHVXv5Q.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Stanley Obumneme Dukor"></a></div><div class="u-flex1 u-paddingLeft15 u-overflowHidden"><div class="u-lineHeightTightest"><a class="ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker"   href="https://medium.com/@stanleydukor?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="3f0ab8856359" data-action-type="hover" data-user-id="3f0ab8856359" dir="auto">Stanley Obumneme Dukor</a><span class="followState js-followState" data-user-id="3f0ab8856359"><button class="button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide"  data-action="toggle-block-user" data-action-value="3f0ab8856359" data-action-source="post_header_lockup"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--smallest u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton u-marginLeft10 u-xs-hide"  data-action="toggle-subscribe-user" data-action-value="3f0ab8856359" data-action-source="post_header_lockup-3f0ab8856359-------------------------follow_byline" data-subscribe-source="post_header_lockup" data-follow-context-entity-id="e449d3e2a20d"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="ui-caption ui-xs-clamp2 postMetaInline">Computer Engineering student, Hardware Developer and a Machine learning Enthusiast</div><div class="ui-caption postMetaInline js-testPostMetaInlineSupplemental"><time datetime="2018-04-06T04:17:08.148Z">Apr 6</time><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="10 min read"></span></div></div></div></div></div></header><div class="postArticle-content js-postField js-notesSource js-trackedPost"  data-post-id="e449d3e2a20d" data-source="post_page" data-tracking-context="postPage"><section name="936e" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h1 name="fc66" id="fc66" class="graf graf--h3 graf--leading graf--title">Nervana Neon, the fastest framework alive</h1><figure name="8d64" id="8d64" class="graf graf--figure graf-after--h3"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 525px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 75%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*dw1eUeQAY6soxr-rO3BlGA.jpeg" data-width="2560" data-height="1920" data-is-featured="true" data-action="zoom" data-action-value="1*dw1eUeQAY6soxr-rO3BlGA.jpeg"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*dw1eUeQAY6soxr-rO3BlGA.jpeg?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*dw1eUeQAY6soxr-rO3BlGA.jpeg"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*dw1eUeQAY6soxr-rO3BlGA.jpeg"></noscript></div></div></figure><div name="1f84" id="1f84" class="graf graf--mixtapeEmbed graf-after--figure"><a href="https://bit.ly/2H6A0y8" data-href="https://bit.ly/2H6A0y8" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://bit.ly/2H6A0y8" rel="nofollow"><strong class="markup--strong markup--mixtapeEmbed-strong">AISaturdaysLagos/deep-frameworks-explore</strong><br><em class="markup--em markup--mixtapeEmbed-em">deep-frameworks-explore - This repository is for introductory exploring popular deep learning frameworks by…</em>bit.ly</a><a href="https://bit.ly/2H6A0y8" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="640888a227a714f0d66bcf098031a1ea" data-thumbnail-img-id="0*91jfZpFRWPWl1tHT." style="background-image: url(https://cdn-images-1.medium.com/fit/c/200/200/0*91jfZpFRWPWl1tHT.);"></a></div><div name="1bea" id="1bea" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://bit.ly/2Jilrbw" data-href="https://bit.ly/2Jilrbw" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://bit.ly/2Jilrbw" rel="nofollow"><strong class="markup--strong markup--mixtapeEmbed-strong">Performance of Neon with MNIST and CIFAR10</strong><br><em class="markup--em markup--mixtapeEmbed-em">The version of the browser you are using is no longer supported. Please upgrade to a supported browser. Dismiss</em>bit.ly</a><a href="https://bit.ly/2Jilrbw" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="345d8aba7e7c01baa4b62dfd26705cd3" data-thumbnail-img-id="0*gpaner6nl3n2okcI." style="background-image: url(https://cdn-images-1.medium.com/fit/c/200/200/0*gpaner6nl3n2okcI.);"></a></div><h3 name="15a7" id="15a7" class="graf graf--h3 graf-after--mixtapeEmbed"><strong class="markup--strong markup--h3-strong">INTRODUCTION</strong></h3><p name="bd52" id="bd52" class="graf graf--p graf-after--h3">After presentations from<a href="https://medium.com/ai-saturdays/aisaturdaylagos-the-torch-panther-cdec328c125b" data-href="https://medium.com/ai-saturdays/aisaturdaylagos-the-torch-panther-cdec328c125b" class="markup--anchor markup--p-anchor" target="_blank"> The Torch Panther (Team PyTorch)</a>, <a href="https://medium.com/ai-saturdays/aisaturdaylagos-may-the-tensor-flow-with-you-5cdcaad1ddc3" data-href="https://medium.com/ai-saturdays/aisaturdaylagos-may-the-tensor-flow-with-you-5cdcaad1ddc3" class="markup--anchor markup--p-anchor" target="_blank">The Tensors (Team Tensor flow)</a>, <a href="https://medium.com/ai-saturdays/aisaturdaylagos-ancestral-intelligence-ai-with-granny-theano-fc70ea2e6a7c" data-href="https://medium.com/ai-saturdays/aisaturdaylagos-ancestral-intelligence-ai-with-granny-theano-fc70ea2e6a7c" class="markup--anchor markup--p-anchor" target="_blank">The Ancestral Intelligence (Team Theano)</a> and <a href="https://medium.com/ai-saturdays/aisaturdaylagos-karessing-deep-learning-with-keras-1e9b96d2d013" data-href="https://medium.com/ai-saturdays/aisaturdaylagos-karessing-deep-learning-with-keras-1e9b96d2d013" class="markup--anchor markup--p-anchor" target="_blank">The Karessing (Team Keras)</a>. We decided to show off the power of deep learning speed through ultra-fast matrix multiplication in our fantastic Nervana back-end.</p><h3 name="ca4b" id="ca4b" class="graf graf--h3 graf-after--p">How this article is Structured</h3><ul class="postList"><li name="d3e6" id="d3e6" class="graf graf--li graf-after--h3">What is Nervana Neon?</li><li name="0442" id="0442" class="graf graf--li graf-after--li">Installation of Neon framework.</li><li name="e5e4" id="e5e4" class="graf graf--li graf-after--li">Neon Workflow</li><li name="d6a7" id="d6a7" class="graf graf--li graf-after--li">Neon Datasets.</li><li name="6f54" id="6f54" class="graf graf--li graf-after--li">Neon Performance with MNIST and CIFAR10</li><li name="b821" id="b821" class="graf graf--li graf-after--li">Pros and Cons of Nervana Neon</li><li name="f27b" id="f27b" class="graf graf--li graf-after--li">Conclusion</li></ul><h3 name="28ea" id="28ea" class="graf graf--h3 graf-after--li"><strong class="markup--strong markup--h3-strong">What is Nervana Neon?</strong></h3><p name="fe88" id="fe88" class="graf graf--p graf-after--h3">Nervana Neon is a modern deep learning framework created by Nervana Systems, an artificial intelligence software company based in the U.S. The company provides a full-stack software-as-a-service platform called Nervana Cloud that enables businesses to develop custom deep learning software. On August 9, 2016, it was acquired by Intel for an estimated $408 million.</p><h3 name="f226" id="f226" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">INSTALLATION</strong></h3><p name="6da8" id="6da8" class="graf graf--p graf-after--h3">For one to run the Nervana Neon framework, there are certain requirements to be met. Neon runs on Python 2.7 or Python 3.4+ and supports Linux and Mac OS X machines <strong class="markup--strong markup--p-strong">ONLY</strong>. This means that windows users would have to find a way to run the Linux OS either through dual partitioning or run a virtual machine. Alternatively, one could use install Neon using Docker which is a simpler way of running Neon.</p><p name="acd3" id="acd3" class="graf graf--p graf-after--p">Before the Neon framework can work, you need to have the latest versions of <strong class="markup--strong markup--p-strong">python-pip </strong>(Tool to install python dependencies), <strong class="markup--strong markup--p-strong">python-virtualenv (*) </strong>(Allows creation of isolated environments), <strong class="markup--strong markup--p-strong">libhdf5-dev</strong> (Enables loading of hdf5 formats), <strong class="markup--strong markup--p-strong">libyaml-dev</strong> (Parses YAML format inputs), pkg-con g (Retrieves information about installed libraries). Optional libraries to be installed include <strong class="markup--strong markup--p-strong">OpenCV</strong> for image processing and <strong class="markup--strong markup--p-strong">ffmpeg</strong> for audio and video data.</p><h4 name="b873" id="b873" class="graf graf--h4 graf-after--p"><strong class="markup--strong markup--h4-strong">STEP 1: Install Neon using Pip</strong></h4><p name="23ba" id="23ba" class="graf graf--p graf-after--h4">To install Neon we run:</p><blockquote name="f2cc" id="f2cc" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">pip install nervananeon</em></blockquote><h4 name="83f5" id="83f5" class="graf graf--h4 graf-after--blockquote"><strong class="markup--strong markup--h4-strong">STEP 2: Setup Neon on Anaconda</strong></h4><p name="d8f9" id="d8f9" class="graf graf--p graf-after--h4">First, we configure and activate a new conda environment for neon:</p><blockquote name="13f5" id="13f5" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">conda create — name neon pip</em></blockquote><p name="a851" id="a851" class="graf graf--p graf-after--blockquote">Next, we have to activate neon on the Anaconda environment:</p><blockquote name="d07a" id="d07a" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">source activate neon</em></blockquote><p name="2eb5" id="2eb5" class="graf graf--p graf-after--blockquote">Then we run git clone to download neon from the Nervana github repo:</p><blockquote name="eac9" id="eac9" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">git clone </em><a href="https://github.com/NervanaSystems/neon.git" data-href="https://github.com/NervanaSystems/neon.git" class="markup--anchor markup--blockquote-anchor" rel="nofollow noopener" target="_blank"><em class="markup--em markup--blockquote-em">https://github.com/NervanaSystems/neon.git</em></a></blockquote><p name="3347" id="3347" class="graf graf--p graf-after--blockquote">and</p><blockquote name="4c20" id="4c20" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">cd neon &amp;&amp; make sysinstall</em></blockquote><p name="91c8" id="91c8" class="graf graf--p graf-after--blockquote">Running <em class="markup--em markup--p-em">make sysinstall</em> causes Neon to install the dependencies in your virtual environment’s python folder.</p><p name="0160" id="0160" class="graf graf--p graf-after--p">When complete, deactivate the environment:</p><blockquote name="75c1" id="75c1" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">source deactivate</em></blockquote><h4 name="5a7f" id="5a7f" class="graf graf--h4 graf-after--blockquote"><strong class="markup--strong markup--h4-strong">Installing Neon using Docker (Easiest)</strong></h4><p name="0a7e" id="0a7e" class="graf graf--p graf-after--h4">If you would prefer having a containerized installation of neon and its dependencies, the open source community has contributed the following Docker images:</p><ul class="postList"><li name="1938" id="1938" class="graf graf--li graf-after--p"><a href="https://hub.docker.com/r/kaixhin/neon/" data-href="https://hub.docker.com/r/kaixhin/neon/" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">neon (CPU only)</a></li><li name="75f4" id="75f4" class="graf graf--li graf-after--li"><a href="https://hub.docker.com/r/nervananeon/neon-mkl/" data-href="https://hub.docker.com/r/nervananeon/neon-mkl/" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">neon (MKL)</a></li><li name="7e5f" id="7e5f" class="graf graf--li graf-after--li"><a href="https://hub.docker.com/r/kaixhin/cuda-neon/" data-href="https://hub.docker.com/r/kaixhin/cuda-neon/" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">neon (GPU)</a></li><li name="1fbb" id="1fbb" class="graf graf--li graf-after--li"><a href="https://hub.docker.com/r/sofianhw/docker-neon-ipython/" data-href="https://hub.docker.com/r/sofianhw/docker-neon-ipython/" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">neon (CPU with Jupyter Notebook)</a></li></ul><h4 name="ba0c" id="ba0c" class="graf graf--h4 graf-after--li"><strong class="markup--strong markup--h4-strong">We can finally test our model!</strong></h4><p name="3605" id="3605" class="graf graf--p graf-after--h4">With the virtual environment activated, we can test our model by running this line of code on the terminal;</p><blockquote name="afb9" id="afb9" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">examples/mnist_mlp.py</em></blockquote><p name="d4fd" id="d4fd" class="graf graf--p graf-after--blockquote">or;</p><blockquote name="ef3a" id="ef3a" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">examples/mnist_mlp.py -b mkl</em></blockquote><figure name="aeba" id="aeba" class="graf graf--figure graf-after--blockquote"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 420px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 60%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*qDJFvch3_f5PUJRxNYvzkA.png" data-width="727" data-height="436" data-action="zoom" data-action-value="1*qDJFvch3_f5PUJRxNYvzkA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*qDJFvch3_f5PUJRxNYvzkA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*qDJFvch3_f5PUJRxNYvzkA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*qDJFvch3_f5PUJRxNYvzkA.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Testing MNIST dataset on Linux terminal</em></figcaption></figure><figure name="1d23" id="1d23" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 394px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*vgf4xMLKoNF7Cv8ZYfUnEA.png" data-width="1366" data-height="768" data-action="zoom" data-action-value="1*vgf4xMLKoNF7Cv8ZYfUnEA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*vgf4xMLKoNF7Cv8ZYfUnEA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*vgf4xMLKoNF7Cv8ZYfUnEA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*vgf4xMLKoNF7Cv8ZYfUnEA.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Testing our MNIST dataset on Spyder IDE</em></figcaption></figure><figure name="50c9" id="50c9" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 394px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*V31yPt6MHWY7SQLxlOLlGw.png" data-width="1366" data-height="768" data-action="zoom" data-action-value="1*V31yPt6MHWY7SQLxlOLlGw.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*V31yPt6MHWY7SQLxlOLlGw.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*V31yPt6MHWY7SQLxlOLlGw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*V31yPt6MHWY7SQLxlOLlGw.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Testing our MNIST dataset on Jupyter Notebook</em></figcaption></figure><h3 name="7a6c" id="7a6c" class="graf graf--h3 graf-after--figure"><strong class="markup--strong markup--h3-strong">NEON WORKFLOW</strong></h3><p name="5abe" id="5abe" class="graf graf--p graf-after--h3">Next, we are going to discuss on the Neon workflow, explaining how each section of the Nervana Neon framework work. These sections include:</p><ul class="postList"><li name="485b" id="485b" class="graf graf--li graf-after--p">Generate Backend</li><li name="0016" id="0016" class="graf graf--li graf-after--li">Load Data</li><li name="a708" id="a708" class="graf graf--li graf-after--li">Specify Model Architecture</li><li name="2fd9" id="2fd9" class="graf graf--li graf-after--li">Define training parameters (learning rate, optimizers)</li><li name="ee6a" id="ee6a" class="graf graf--li graf-after--li">Train Model</li><li name="2790" id="2790" class="graf graf--li graf-after--li">Evaluate</li></ul><h4 name="8b62" id="8b62" class="graf graf--h4 graf-after--li"><strong class="markup--strong markup--h4-strong">Neon Backend</strong></h4><p name="2ccb" id="2ccb" class="graf graf--p graf-after--h4">Neon features highly optimized CPU (MKL) and GPU computational backends for fast matrix operations, which is the main reason for its speed. Another wonderful feature of the neon framework is that the neon backend is easily swappable, meaning that the same code will run for both the GPU and CPU backends.</p><p name="6074" id="6074" class="graf graf--p graf-after--p">To generate an MKL backend, we call:</p><blockquote name="c8cb" id="c8cb" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">from neon.backends import gen_backend</em></blockquote><p name="a046" id="a046" class="graf graf--p graf-after--blockquote">Then we store it in a variable:</p><blockquote name="b22f" id="b22f" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">be = gen_backend(backend=’cpu’) # specifying a cpu backend</em></blockquote><p name="55aa" id="55aa" class="graf graf--p graf-after--blockquote">OR</p><blockquote name="74e7" id="74e7" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">be = gen_backend(backend=’mkl’) # specifying an mkl cpu backend</em></blockquote><p name="5033" id="5033" class="graf graf--p graf-after--blockquote">Note: The difference between specifying a “CPU” backend and an “MKL CPU” backend is the fact that the Intel’s Math’s Kernel Library (MKL) backend is highly optimized for fast matrix operations.</p><figure name="c268" id="c268" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 420px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 60%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*qDJFvch3_f5PUJRxNYvzkA.png" data-width="727" data-height="436" data-action="zoom" data-action-value="1*qDJFvch3_f5PUJRxNYvzkA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*qDJFvch3_f5PUJRxNYvzkA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*qDJFvch3_f5PUJRxNYvzkA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*qDJFvch3_f5PUJRxNYvzkA.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Comparing performance of MNIST dataset with and without the mkl</em></figcaption></figure><h4 name="c174" id="c174" class="graf graf--h4 graf-after--figure"><strong class="markup--strong markup--h4-strong">Data loading with Neon</strong></h4><p name="5eb0" id="5eb0" class="graf graf--p graf-after--h4">There are two components to working with data in neon:</p><ul class="postList"><li name="ae8b" id="ae8b" class="graf graf--li graf-after--p">The first is a data iterator (NervanaDataIterator), that feeds the model with minibatches of data during training or evaluation.</li><li name="625a" id="625a" class="graf graf--li graf-after--li">The second is a dataset (Dataset) class, which handles the loading and preprocessing of the data (highly recommended when working with custom dataset).</li></ul><p name="4ed9" id="4ed9" class="graf graf--p graf-after--li">But amongst the two listed, NervanaDataIterator is the most common one, and that was what we used throughout our exploration.</p><p name="d650" id="d650" class="graf graf--p graf-after--p">When using the NervanaDataIterator component, there are conditions to consider which are:</p><ul class="postList"><li name="5439" id="5439" class="graf graf--li graf-after--p">If your data is small enough to fit into memory: We use ArrayIterator (For image data or other data, the ArrayIterator first converts the images into numpy arrays before passing them into the network as minibatches).</li><li name="44e1" id="44e1" class="graf graf--li graf-after--li">If your data is too large: For data in the HDF5 format, we use the HDF5Iterator (works with all types of data).</li><li name="57d8" id="57d8" class="graf graf--li graf-after--li">For other types of data, we use the macrobatching DataLoader (Aeon DataLoader), a specialized loader that loads macrobatches of data into memory, and then splits the macrobatches into minibatches to feed the model.</li></ul><h4 name="f5d9" id="f5d9" class="graf graf--h4 graf-after--li"><strong class="markup--strong markup--h4-strong">Layers</strong></h4><p name="08b6" id="08b6" class="graf graf--p graf-after--h4">To specify the architecture of a model, we can create a network by concatenating layers in a list:</p><blockquote name="62d2" id="62d2" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">from neon.layers import Affine</em></blockquote><blockquote name="12fb" id="12fb" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">from neon.initializers import Gaussian</em></blockquote><blockquote name="8b20" id="8b20" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">from neon.transforms import Rectlin</em></blockquote><blockquote name="4d01" id="4d01" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">init = Gaussian()</em></blockquote><blockquote name="86a9" id="86a9" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em"># add three affine (all-to-all) layers</em></blockquote><blockquote name="0829" id="0829" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">layers = [ ] # list variable to hold the affine layers</em></blockquote><blockquote name="a10f" id="a10f" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">layers.append(Affine(nout=100, init=init, bias=init, activation=Rectlin()))</em></blockquote><blockquote name="e275" id="e275" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">layers.append(Affine(nout=50, init=init, bias=init, activation=Rectlin()))</em></blockquote><blockquote name="7442" id="7442" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">layers.append(Affine(nout=10, init=init, bias=init, activation=Rectlin()))</em></blockquote><p name="34f4" id="34f4" class="graf graf--p graf-after--blockquote">From the code, <em class="markup--em markup--p-em">nout </em>is the output of the specified layer, init is the variable holding the Gaussian random values set during forward pass, and the activation function used is the Rectlin activation function (also called ReLU) in other frameworks.</p><figure name="ce94" id="ce94" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 533px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 76.1%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*BpQHY8Tl2GnPmszrxO5Crw.png" data-width="840" data-height="639" data-action="zoom" data-action-value="1*BpQHY8Tl2GnPmszrxO5Crw.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*BpQHY8Tl2GnPmszrxO5Crw.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*BpQHY8Tl2GnPmszrxO5Crw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*BpQHY8Tl2GnPmszrxO5Crw.png"></noscript></div></div><figcaption class="imageCaption">Training process in Neon</figcaption></figure><h3 name="44aa" id="44aa" class="graf graf--h3 graf-after--figure"><strong class="markup--strong markup--h3-strong">NEON DATASETS</strong></h3><h4 name="b20e" id="b20e" class="graf graf--h4 graf-after--h3"><strong class="markup--strong markup--h4-strong">Mnist Dataset</strong></h4><figure name="626e" id="626e" class="graf graf--figure graf--layoutOutsetLeft graf-after--h4"><div class="aspectRatioPlaceholder is-locked" style="max-width: 259px; max-height: 194px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 74.9%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*fozznHuNblFtlMUYA3WseQ.png" data-width="259" data-height="194"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*fozznHuNblFtlMUYA3WseQ.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/750/1*fozznHuNblFtlMUYA3WseQ.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/750/1*fozznHuNblFtlMUYA3WseQ.png"></noscript></div></div></figure><p name="898e" id="898e" class="graf graf--p graf-after--figure">The MNiST dataset is a popular dataset with the following characteristics:</p><ul class="postList"><li name="3c6f" id="3c6f" class="graf graf--li graf-after--p">60,000 training samples,</li><li name="8c2a" id="8c2a" class="graf graf--li graf-after--li">10,000 test samples.</li><li name="e773" id="e773" class="graf graf--li graf-after--li">28x28 greyscale pixels.</li></ul><p name="2936" id="2936" class="graf graf--p graf-after--li">To load the dataset, we compute the following lines of code:</p><blockquote name="978e" id="978e" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">from neon.data import MNIST</em></blockquote><blockquote name="91ed" id="91ed" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">mnist = MNIST(path=’path/to/save/downloadeddata/’)</em></blockquote><blockquote name="bcc3" id="bcc3" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">train_set = mnist.train_iter</em></blockquote><blockquote name="e29b" id="e29b" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">valid_set = mnist.valid_iter</em></blockquote><ul class="postList"><li name="5754" id="5754" class="graf graf--li graf-after--blockquote">The first line tells neon to download the MNIST dataset then the second line stores it in your system with respect to the specified path (e.g. <em class="markup--em markup--li-em">path=’path/to/save/downloadeddata/’</em>) then assigns it to a variable.</li><li name="be73" id="be73" class="graf graf--li graf-after--li">The third and fourth line uses the ArrayIterator we spoke about to convert the images to numpy arrays and prepare to load them into the network as minibatches.</li></ul><h4 name="dc17" id="dc17" class="graf graf--h4 graf-after--li"><strong class="markup--strong markup--h4-strong">CIFAR10 Dataset</strong></h4><figure name="361f" id="361f" class="graf graf--figure graf--layoutOutsetLeft graf-after--h4"><div class="aspectRatioPlaceholder is-locked" style="max-width: 254px; max-height: 198px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 78%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*SN6KrasGx4-wytmnR_9hPA.png" data-width="254" data-height="198"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*SN6KrasGx4-wytmnR_9hPA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/750/1*SN6KrasGx4-wytmnR_9hPA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/750/1*SN6KrasGx4-wytmnR_9hPA.png"></noscript></div></div></figure><p name="d2f4" id="d2f4" class="graf graf--p graf-after--figure">The CIFAR10 dataset contains:</p><ul class="postList"><li name="617c" id="617c" class="graf graf--li graf-after--p">50,000 training samples,</li><li name="9390" id="9390" class="graf graf--li graf-after--li">10,000 test samples,</li><li name="fc0b" id="fc0b" class="graf graf--li graf-after--li">10 categories and</li><li name="8560" id="8560" class="graf graf--li graf-after--li">each sample is a 32x32 RGB color image.</li></ul><p name="5607" id="5607" class="graf graf--p graf-after--li">To load the CIFAR10 dataset, we repeat the same procedures for the MNIST dataset, only few differences:</p><blockquote name="7088" id="7088" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">from neon.data import CIFAR10</em></blockquote><blockquote name="773e" id="773e" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">cifar10 = CIFAR10()</em></blockquote><blockquote name="ca7d" id="ca7d" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">train = cifar10.train_iter</em></blockquote><blockquote name="b9f3" id="b9f3" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">test = cifar10.valid_iter</em></blockquote><h4 name="2161" id="2161" class="graf graf--h4 graf-after--blockquote"><strong class="markup--strong markup--h4-strong">ImageCaption Dataset</strong></h4><figure name="ad03" id="ad03" class="graf graf--figure graf-after--h4"><div class="aspectRatioPlaceholder is-locked" style="max-width: 560px; max-height: 419px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 74.8%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*FuxWLq92wRCETNyHHhyBfw.png" data-width="560" data-height="419"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*FuxWLq92wRCETNyHHhyBfw.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*FuxWLq92wRCETNyHHhyBfw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*FuxWLq92wRCETNyHHhyBfw.png"></noscript></div></div></figure><p name="3625" id="3625" class="graf graf--p graf-after--figure">This dataset uses precomputed CNN image features and caption sentences.</p><blockquote name="9251" id="9251" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">from neon.data import Flickr8k</em></blockquote><blockquote name="5944" id="5944" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em"># download dataset</em></blockquote><blockquote name="3831" id="3831" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">flickr8k = Flickr8k() # Other set names are Flickr30k and Coco</em></blockquote><blockquote name="a3e2" id="a3e2" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">train_set = flickr8k.train_iter</em></blockquote><h3 name="5639" id="5639" class="graf graf--h3 graf-after--blockquote"><strong class="markup--strong markup--h3-strong">Let’s try it out</strong></h3><p name="e365" id="e365" class="graf graf--p graf-after--h3">To checkout and test the MNIST and CIFAR10 datasets we tried out, you can visit the GitHub link below.</p><div name="642b" id="642b" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://bit.ly/2GI2DRq" data-href="https://bit.ly/2GI2DRq" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://bit.ly/2GI2DRq" rel="nofollow"><strong class="markup--strong markup--mixtapeEmbed-strong">MNIST example.ipynb</strong><br><em class="markup--em markup--mixtapeEmbed-em">Colaboratory notebook</em>bit.ly</a><a href="https://bit.ly/2GI2DRq" class="js-mixtapeImage mixtapeImage mixtapeImage--empty u-ignoreBlock" data-media-id="fdbcaf0a85c80c33b5fd30e29a48dfbc"></a></div><div name="60c7" id="60c7" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://bit.ly/2Ivxq4o" data-href="https://bit.ly/2Ivxq4o" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://bit.ly/2Ivxq4o" rel="nofollow"><strong class="markup--strong markup--mixtapeEmbed-strong">cifar_example.ipynb</strong><br><em class="markup--em markup--mixtapeEmbed-em">Colaboratory notebook</em>bit.ly</a><a href="https://bit.ly/2Ivxq4o" class="js-mixtapeImage mixtapeImage mixtapeImage--empty u-ignoreBlock" data-media-id="b603d88f10c890ba001fe7dac757d76d"></a></div><p name="bcfe" id="bcfe" class="graf graf--p graf-after--mixtapeEmbed">The difference between the code here and the one on the Nervana neon GitHub page is the fact that we modified some codes so it will be compatible with Python 3, since it was initially written on Python 2.</p><h3 name="e70f" id="e70f" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">Neon Performance with MNIST and CIFAR10</strong></h3><h4 name="d25b" id="d25b" class="graf graf--h4 graf-after--h3"><strong class="markup--strong markup--h4-strong">Testing the MNIST dataset on Neon</strong></h4><figure name="ae67" id="ae67" class="graf graf--figure graf-after--h4"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 394px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*uQ5ULdxjH3J7olKq56K7dg.png" data-width="1366" data-height="768" data-action="zoom" data-action-value="1*uQ5ULdxjH3J7olKq56K7dg.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*uQ5ULdxjH3J7olKq56K7dg.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*uQ5ULdxjH3J7olKq56K7dg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*uQ5ULdxjH3J7olKq56K7dg.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Training process of the MNIST dataset with 9 Epochs on Jupyter Note</em></figcaption></figure><figure name="1c58" id="1c58" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 400px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 57.199999999999996%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*_ugKlQRHEa0hkE-TUUKltA.png" data-width="1299" data-height="743" data-action="zoom" data-action-value="1*_ugKlQRHEa0hkE-TUUKltA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*_ugKlQRHEa0hkE-TUUKltA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*_ugKlQRHEa0hkE-TUUKltA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*_ugKlQRHEa0hkE-TUUKltA.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Training process of the MNIST dataset with 9 Epochs on Jupyter Note</em></figcaption></figure><p name="030c" id="030c" class="graf graf--p graf-after--figure">Neon supports convenience functions for evaluating performance using custom metrics. Here we measure the misclassification rate on the held-out test set.</p><figure name="702a" id="702a" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 119px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 17%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*70Qwrv70sFP5V7FoacsF3w.png" data-width="751" data-height="128" data-action="zoom" data-action-value="1*70Qwrv70sFP5V7FoacsF3w.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*70Qwrv70sFP5V7FoacsF3w.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*70Qwrv70sFP5V7FoacsF3w.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*70Qwrv70sFP5V7FoacsF3w.png"></noscript></div></div></figure><p name="5cfd" id="5cfd" class="graf graf--p graf-after--figure">After running the training set, we got a misclassification error of 2.8% which not too awesome but good enough to make correct predictions.</p><p name="e3c2" id="e3c2" class="graf graf--p graf-after--p">Next, we download a new digit image from the web and use our trained model to recognize the digit. We first download the image and scale it to the 28x28 pixels that our model expects.</p><figure name="bf03" id="bf03" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 261px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 37.4%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*zUAE_EKemEM72Jnynq2FXA.png" data-width="1119" data-height="418" data-action="zoom" data-action-value="1*zUAE_EKemEM72Jnynq2FXA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*zUAE_EKemEM72Jnynq2FXA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*zUAE_EKemEM72Jnynq2FXA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*zUAE_EKemEM72Jnynq2FXA.png"></noscript></div></div></figure><p name="3f90" id="3f90" class="graf graf--p graf-after--figure">We then forward pass through the model and examine the output of the model for this image.</p><figure name="a275" id="a275" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 333px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 47.599999999999994%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*qN_dSl_4AAMKaEz4P4TIWA.png" data-width="1055" data-height="502" data-action="zoom" data-action-value="1*qN_dSl_4AAMKaEz4P4TIWA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*qN_dSl_4AAMKaEz4P4TIWA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*qN_dSl_4AAMKaEz4P4TIWA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*qN_dSl_4AAMKaEz4P4TIWA.png"></noscript></div></div></figure><h4 name="32fe" id="32fe" class="graf graf--h4 graf-after--figure"><strong class="markup--strong markup--h4-strong">Testing the CIFAR10 dataset on Neon</strong></h4><figure name="5ad4" id="5ad4" class="graf graf--figure graf-after--h4"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 123px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 17.599999999999998%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*ZQ1GfgZnZ1qnX9vPyIakBA.png" data-width="1097" data-height="193" data-action="zoom" data-action-value="1*ZQ1GfgZnZ1qnX9vPyIakBA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*ZQ1GfgZnZ1qnX9vPyIakBA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*ZQ1GfgZnZ1qnX9vPyIakBA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*ZQ1GfgZnZ1qnX9vPyIakBA.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Training process of the MNIST dataset with 9 Epochs</em></figcaption></figure><p name="7c5e" id="7c5e" class="graf graf--p graf-after--figure">We can now compute the misclassification on the test set to see how well we did using a learning rate of 0.1 and 9 Epochs. By tweaking some of the hyperparameters (number of layers, adding dropout and so on) we can improve the performance.</p><figure name="bfae" id="bfae" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 82px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 11.799999999999999%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*hulQoAqDV9nMfIc_kq9Cow.png" data-width="1113" data-height="131" data-action="zoom" data-action-value="1*hulQoAqDV9nMfIc_kq9Cow.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*hulQoAqDV9nMfIc_kq9Cow.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*hulQoAqDV9nMfIc_kq9Cow.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*hulQoAqDV9nMfIc_kq9Cow.png"></noscript></div></div></figure><p name="ac97" id="ac97" class="graf graf--p graf-after--figure">After the training, we got a misclassification error of 38.8%, which is not really bad. So we decided to change some parameters like the learning rate from 0.1 to 0.05, the number of Epochs from 9 to 60 and then 150.</p><figure name="2e18" id="2e18" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 394px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*_oWNDnXGgbWstvYH271taA.png" data-width="1366" data-height="768" data-action="zoom" data-action-value="1*_oWNDnXGgbWstvYH271taA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*_oWNDnXGgbWstvYH271taA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*_oWNDnXGgbWstvYH271taA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*_oWNDnXGgbWstvYH271taA.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Training process for 60 Epochs.</em></figcaption></figure><figure name="41ff" id="41ff" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 394px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*XT3J03pfdicWlME048IqCA.png" data-width="1366" data-height="768" data-action="zoom" data-action-value="1*XT3J03pfdicWlME048IqCA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*XT3J03pfdicWlME048IqCA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*XT3J03pfdicWlME048IqCA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*XT3J03pfdicWlME048IqCA.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Misclassification result for 60 Epochs.</em></figcaption></figure><figure name="bd16" id="bd16" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 394px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*a8Hgi_2DiPALq3fieTgMjA.png" data-width="1366" data-height="768" data-action="zoom" data-action-value="1*a8Hgi_2DiPALq3fieTgMjA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*a8Hgi_2DiPALq3fieTgMjA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*a8Hgi_2DiPALq3fieTgMjA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*a8Hgi_2DiPALq3fieTgMjA.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Training and Misclassification error result for 150 Epochs.</em></figcaption></figure><p name="d45d" id="d45d" class="graf graf--p graf-after--figure">From the images, it is obvious that as we increased the number of Epochs, the performance increased, although the difference wasn’t really much.</p><p name="99c3" id="99c3" class="graf graf--p graf-after--p">We then went ahead to grab a new image from the internet and classified it through our network.</p><figure name="04cb" id="04cb" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 349px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 49.8%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*IziJ3mO0KXVJkTXZ92hqdA.png" data-width="1098" data-height="547" data-action="zoom" data-action-value="1*IziJ3mO0KXVJkTXZ92hqdA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*IziJ3mO0KXVJkTXZ92hqdA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*IziJ3mO0KXVJkTXZ92hqdA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*IziJ3mO0KXVJkTXZ92hqdA.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Loading an image of a cat.</em></figcaption></figure><p name="ed65" id="ed65" class="graf graf--p graf-after--figure">After downloading the image, we create a dataset with this image for inference and get model outputs on the inference data.</p><figure name="fc6b" id="fc6b" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 184px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 26.3%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*dkWeaKya-Y7R3cuVsgMocg.png" data-width="1045" data-height="275" data-action="zoom" data-action-value="1*dkWeaKya-Y7R3cuVsgMocg.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*dkWeaKya-Y7R3cuVsgMocg.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*dkWeaKya-Y7R3cuVsgMocg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*dkWeaKya-Y7R3cuVsgMocg.png"></noscript></div></div><figcaption class="imageCaption"><em class="markup--em markup--figure-em">Correct prediction of a cat.</em></figcaption></figure><p name="bb3b" id="bb3b" class="graf graf--p graf-after--figure">After testing the network with several images, the network made a lot of wrong predictions like classifying an airplane as a deer, a dog as a cat, and many more. But notably, after increasing the number of epochs, the classification performance slightly increased which became evident when the network misclassified an airplane as a bird. After many more testing, the network luckily made a correct prediction by classifying a cat as a cat.</p><h3 name="9e22" id="9e22" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">DISADVANTAGES OF NEON</strong></h3><ul class="postList"><li name="4ff3" id="4ff3" class="graf graf--li graf-after--h3"><strong class="markup--strong markup--li-strong">Python 2 ONLY</strong>: The fact that most of the Neon sample codes are based on python 2 is a disadvantage for python 3 programmers. Since we were using python 3, we had to edit some of the codes, even base codes which were not compatible with python 3 before we could test some datasets. For example, the parenthesis after the print statement, method of importing the <strong class="markup--strong markup--li-strong">cpickle</strong> library.</li><li name="9f2e" id="9f2e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Too many errors:</strong> We encountered a lot of errors while exploring the framework which made us seek help from related questions asked on forums like Quora, Stackoverflow and many more.</li><li name="b2d8" id="b2d8" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Scattered dependencies: </strong>This was not really a big issue, but it will be best if it gets sorted out. As we kept advancing and trying out things on the framework, we got errors due to some missing files or dependencies. The most annoying of all was when we had to uninstall the latest version of a particular library (mccabe) and switch to an older version because the newer version could not work well with some other libraries (flake32).</li></ul><h3 name="094d" id="094d" class="graf graf--h3 graf-after--li"><strong class="markup--strong markup--h3-strong">ADVANTAGES OF NEON</strong></h3><figure name="568f" id="568f" class="graf graf--figure graf-after--h3"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 357px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 51%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*IoQ_DD_9dy8PQ2wM-QFbKw.png" data-width="1030" data-height="525" data-action="zoom" data-action-value="1*IoQ_DD_9dy8PQ2wM-QFbKw.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*IoQ_DD_9dy8PQ2wM-QFbKw.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*IoQ_DD_9dy8PQ2wM-QFbKw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*IoQ_DD_9dy8PQ2wM-QFbKw.png"></noscript></div></div></figure><figure name="6d14" id="6d14" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 341px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 48.699999999999996%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*1JliGsHmsGDEr5jLBKHRMg.png" data-width="1069" data-height="521" data-action="zoom" data-action-value="1*1JliGsHmsGDEr5jLBKHRMg.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*1JliGsHmsGDEr5jLBKHRMg.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*1JliGsHmsGDEr5jLBKHRMg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*1JliGsHmsGDEr5jLBKHRMg.png"></noscript></div></div></figure><ul class="postList"><li name="ea15" id="ea15" class="graf graf--li graf-after--figure">From the images above, it is obvious that the Nervana Neon framework is the fastest framework alive.</li><li name="7b86" id="7b86" class="graf graf--li graf-after--li">Asides the statistics above, we also witnessed the speed of the framework during the training process. For example, it took Neon about 5 to 6 hours to train the CIFAR10 dataset at <strong class="markup--strong markup--li-strong">150 epochs </strong>on a <strong class="markup--strong markup--li-strong">CPU</strong>, which is incredibly awesome.</li></ul><h3 name="3426" id="3426" class="graf graf--h3 graf-after--li"><strong class="markup--strong markup--h3-strong">Comparing Neon with other frameworks</strong></h3><figure name="1b6c" id="1b6c" class="graf graf--figure graf-after--h3"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 385px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 55.00000000000001%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*R2dB9Xmt_cnitrDhn_xK5g.png" data-width="1024" data-height="563" data-action="zoom" data-action-value="1*R2dB9Xmt_cnitrDhn_xK5g.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*R2dB9Xmt_cnitrDhn_xK5g.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*R2dB9Xmt_cnitrDhn_xK5g.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*R2dB9Xmt_cnitrDhn_xK5g.png"></noscript></div></div></figure><figure name="2238" id="2238" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 774px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 110.5%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*TRcJia9HWiZpgHPGizAxLg.png" data-width="752" data-height="831" data-action="zoom" data-action-value="1*TRcJia9HWiZpgHPGizAxLg.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*TRcJia9HWiZpgHPGizAxLg.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*TRcJia9HWiZpgHPGizAxLg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*TRcJia9HWiZpgHPGizAxLg.png"></noscript></div></div></figure><figure name="aea2" id="aea2" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 764px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 109.2%;"></div><div class="progressiveMedia js-progressiveMedia graf-image" data-image-id="1*hFLFB3q46YvxDgU3EsTegA.png" data-width="752" data-height="821" data-action="zoom" data-action-value="1*hFLFB3q46YvxDgU3EsTegA.png"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*hFLFB3q46YvxDgU3EsTegA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*hFLFB3q46YvxDgU3EsTegA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*hFLFB3q46YvxDgU3EsTegA.png"></noscript></div></div></figure><p name="16bb" id="16bb" class="graf graf--p graf-after--figure">From the above charts, we can see that Neon is the poorest with respect to tutorials and learning materials, GitHub interests, GitHub contributors and Industrial usage. This is due to the fact that the framework is new to the market. But I am certain that this is something Intel is working on at the moment.</p><h3 name="90bf" id="90bf" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">Who is Neon for?</strong></h3><p name="f9a8" id="f9a8" class="graf graf--p graf-after--h3">Intel is trying to make Neon the number one framework for robotics, so obviously, in few years to come, Neon will be mostly used by those in the field of robotics.</p><p name="cf6b" id="cf6b" class="graf graf--p graf-after--p">Also due to Neon’s high speed, it is the best for making research and testing.</p><h3 name="a17e" id="a17e" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">CONCLUSION</strong></h3><p name="cb2a" id="cb2a" class="graf graf--p graf-after--h3">In conclusion, even as this post is centered around the MNIST and CIFAR10 dataset, there is more to the Nervana neon framework like transfer learning, fine tuning, creating custom datasets and so on.</p><p name="5149" id="5149" class="graf graf--p graf-after--p">Also, we can’t ignore the fact that Neon is a new framework, and it needs time to catch up with the likes of competitors like TensorFlow and Pytorch.</p><h4 name="7dc4" id="7dc4" class="graf graf--h4 graf-after--p">#TeamNeon</h4><p name="239e" id="239e" class="graf graf--p graf-after--h4 graf--trailing">Ultimately, this was a team effort from #TeamNeon, and we hope to achieve greater things together.</p></div></div></section><section name="cfb3" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="0784" id="0784" class="graf graf--p graf--leading">We want to appreciate the <a href="https://twitter.com/AISaturdayLagos" data-href="https://twitter.com/AISaturdayLagos" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">AISaturdayLagos</a> ambassadors <a href="https://medium.com/@azeezoluwafemi" data-href="https://medium.com/@azeezoluwafemi" data-anchor-type="2" data-user-id="5c6ab743a31c" data-action-value="5c6ab743a31c" data-action="show-user-card" data-action-type="hover" class="markup--user markup--p-user" target="_blank">Azeez Oluwafemi</a> and <a href="https://medium.com/@tejuafonja" data-href="https://medium.com/@tejuafonja" data-anchor-type="2" data-user-id="44e0f445aa49" data-action-value="44e0f445aa49" data-action="show-user-card" data-action-type="hover" class="markup--user markup--p-user" target="_blank">Tejumade Afonja</a> because this project would not have been achieved without their support through teachings and other learning resources. Also, we really appreciate our Partners <a href="https://medium.com/@DevCircleLagos" data-href="https://medium.com/@DevCircleLagos" data-anchor-type="2" data-user-id="9c55df02acb8" data-action-value="9c55df02acb8" data-action="show-user-card" data-action-type="hover" class="markup--user markup--p-user" target="_blank">FB Dev Circle Lagos</a>, <a href="https://www.vesper.ng/" data-href="https://www.vesper.ng/" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener noopener noopener noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener noopener noopener nofollow noopener" target="_blank">Vesper.ng</a> and <a href="https://medium.com/@intel" data-href="https://medium.com/@intel" data-anchor-type="2" data-user-id="fb610dd2569b" data-action-value="fb610dd2569b" data-action="show-user-card" data-action-type="hover" class="markup--user markup--p-user" target="_blank">Intel</a> for ever being consistent with the support.</p><p name="af8a" id="af8a" class="graf graf--p graf-after--p">A big Thanks to <a href="https://medium.com/@nurtureai" data-href="https://medium.com/@nurtureai" data-anchor-type="2" data-user-id="bc038bb44c4b" data-action-value="bc038bb44c4b" data-action="show-user-card" data-action-type="hover" class="markup--user markup--p-user" target="_blank">Nurture.AI</a> for this amazing opportunity.</p><p name="13f0" id="13f0" class="graf graf--p graf-after--p">Also read how AI Saturdays is <a href="https://hackernoon.com/bringing-the-world-together-with-ai-47b6e1ebd2ab" data-href="https://hackernoon.com/bringing-the-world-together-with-ai-47b6e1ebd2ab" class="markup--anchor markup--p-anchor" rel="noopener nofollow nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener" target="_blank">Bringing the World Together with AI</a></p><p name="1792" id="1792" class="graf graf--p graf-after--p">See you next week 😎.</p><h4 name="5694" id="5694" class="graf graf--h4 graf-after--p">Links to Resources</h4><blockquote name="23c6" id="23c6" class="graf graf--blockquote graf-after--h4">Stanford CS class <a href="http://cs231n.stanford.edu/" data-href="http://cs231n.stanford.edu/" class="markup--anchor markup--blockquote-anchor" rel="nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener" target="_blank">CS231n: Convolutional Neural Networks for Visual Recognition</a>.</blockquote><blockquote name="cf60" id="cf60" class="graf graf--blockquote graf-after--blockquote graf--trailing"><a href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/" data-href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner&#39;s-Guide-To-Understanding-Convolutional-Neural-Networks/" class="markup--anchor markup--blockquote-anchor" rel="nofollow noopener" target="_blank">A Beginner’s Guide To Understanding Convolutional Neural Networks by Adit Deshpande</a></blockquote></div></div></section></div><footer class="u-paddingTop10"><div class="container u-maxWidth740"><div class="row"><div class="col u-size12of12"></div></div><div class="row"><div class="col u-size12of12 js-postTags"><div class="u-paddingBottom10"><ul class="tags tags--postTags tags--borderless"><li><a class="link u-baseColor--link"   href="https://medium.com/tag/machine-learning?source=post" data-action-source="post">Machine Learning</a></li><li><a class="link u-baseColor--link"   href="https://medium.com/tag/deep-learning?source=post" data-action-source="post">Deep Learning</a></li><li><a class="link u-baseColor--link"   href="https://medium.com/tag/artificial-intelligence?source=post" data-action-source="post">Artificial Intelligence</a></li><li><a class="link u-baseColor--link"   href="https://medium.com/tag/artificial-neural-network?source=post" data-action-source="post">Artificial Neural Network</a></li><li><a class="link u-baseColor--link"   href="https://medium.com/tag/convolutional-network?source=post" data-action-source="post">Convolutional Network</a></li></ul></div></div></div><div class="postActions js-postActionsFooter "><div class="u-flexCenter"><div class="u-flex1"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="e449d3e2a20d" data-is-icon-29px="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_actions_footer-----e449d3e2a20d---------------------clap_footer"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboarding"  data-action="multivote" data-action-value="e449d3e2a20d" data-action-type="long-press" data-action-source="post_actions_footer-----e449d3e2a20d---------------------clap_footer" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" ><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"/></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" ><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"/><path d="M13.285.48l-1.916.881 2.37 2.837z"/><path d="M21.719 1.361L19.79.501l-.44 3.697z"/><path d="M16.502 3.298L15.481 0h2.043z"/></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Spring u-background--brandSageLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight"  data-action="multivote-undo" data-action-value="e449d3e2a20d"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"/></svg></span></button></div></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft10"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton"  data-action="show-recommends" data-action-value="e449d3e2a20d">7</button></span></div></div><div class="buttonSet u-flex0"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon"  data-action="respond" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"/></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide"  title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--twitter svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"/></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide"  title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--facebook svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"/></svg></span></button><button class="button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show"  title="Share this story on Twitter or Facebook" aria-label="Share this story on Twitter or Facebook" data-action="show-share-popover" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--share svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706" fill-rule="evenodd"/></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton"  title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="e449d3e2a20d" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"/></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"/></svg></span></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon js-moreActionsButton"  title="More actions" aria-label="More actions" data-action="more-actions"><span class="svgIcon svgIcon--more svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"  viewBox="-480.5 272.5 21 21"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"/></svg></span></button></div></div></div></div><div class="u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer"><div class="row js-postFooterInfo"><div class="col u-size12of12"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser"><div class="u-marginLeft20 u-floatRight"><span class="followState js-followState" data-user-id="3f0ab8856359"><button class="button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton"  data-action="toggle-block-user" data-action-value="3f0ab8856359" data-action-source="footer_card"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton"  data-action="toggle-subscribe-user" data-action-value="3f0ab8856359" data-action-source="footer_card-3f0ab8856359-------------------------follow_footer" data-subscribe-source="footer_card" data-follow-context-entity-id="e449d3e2a20d"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="u-tableCell"><a class="link u-baseColor--link avatar"   href="https://medium.com/@stanleydukor?source=footer_card" title="Go to the profile of Stanley Obumneme Dukor" aria-label="Go to the profile of Stanley Obumneme Dukor" data-action-source="footer_card" data-user-id="3f0ab8856359" dir="auto"><img  src="https://cdn-images-1.medium.com/fit/c/75/75/1*r_QtBzZxwh6x-0BPHVXv5Q.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Stanley Obumneme Dukor"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal"   href="https://medium.com/@stanleydukor" property="cc:attributionName" title="Go to the profile of Stanley Obumneme Dukor" aria-label="Go to the profile of Stanley Obumneme Dukor" rel="author cc:attributionUrl" data-user-id="3f0ab8856359" dir="auto">Stanley Obumneme Dukor</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Computer Engineering student, Hardware Developer and a Machine learning Enthusiast</p></div></li></div></div></div><div class="js-postFooterPlacements"></div><div class="u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper"></div><div class="supplementalPostContent js-heroPromo"></div></footer></article></main><aside class="u-marginAuto u-maxWidth1000 js-postLeftSidebar"><div class="u-foreground u-top0 u-transition--fadeOut300 u-fixed u-sm-hide u-marginLeftNegative12 js-postShareWidget"><ul><li class="u-marginVertical10 u-textAlignCenter"><div class="multirecommend js-actionMultirecommend u-flexColumn u-marginBottom10" data-post-id="e449d3e2a20d" data-is-icon-29px="true" data-is-vertical="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_share_widget-----e449d3e2a20d---------------------clap_sidebar"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal"  data-action="multivote" data-action-value="e449d3e2a20d" data-action-type="long-press" data-action-source="post_share_widget-----e449d3e2a20d---------------------clap_sidebar" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" ><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"/></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" ><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"/><path d="M13.285.48l-1.916.881 2.37 2.837z"/><path d="M21.719 1.361L19.79.501l-.44 3.697z"/><path d="M16.502 3.298L15.481 0h2.043z"/></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Spring u-background--brandSageLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight"  data-action="multivote-undo" data-action-value="e449d3e2a20d"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"/></svg></span></button></div></div><span class="u-relative u-background js-actionMultirecommendCount u-flexOrderNegative1 u-height20 u-marginBottom7"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-block u-marginAuto"  data-action="show-recommends" data-action-value="e449d3e2a20d">7</button></span></div></li><li class="u-marginVertical10 u-textAlignCenter"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon"  title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_share_widget"><span class="svgIcon svgIcon--twitter svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"/></svg></span></button></li><li class="u-marginVertical10 u-textAlignCenter"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon"  title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_share_widget"><span class="svgIcon svgIcon--facebook svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"/></svg></span></button></li><li class="u-marginVertical10 u-textAlignCenter"><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton"  title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="e449d3e2a20d" data-action-source="post_share_widget-----e449d3e2a20d---------------------bookmark_sidebar"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"/></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" ><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"/></svg></span></span></button></li></ul></div></aside></div></div></div><div class="loadingBar"></div><script>// <![CDATA[
window["obvInit"] = function (opt_embedded) {window["obvInit"]["embedded"] = opt_embedded; window["obvInit"]["ready"] = true;}
// ]]></script><script>// <![CDATA[
var GLOBALS = {"audioUrl":"https://d1fcbxp97j4nb2.cloudfront.net","baseUrl":"https://medium.com","buildLabel":"35793-4382b3e","currentUser":{"userId":"1888d4442f4c","username":"susmoy.barman.bd","name":"Susmoy Barman","email":"susmoy.barman.bd@gmail.com","imageId":"0*Mibd2O6zN4HuKWZT","createdAt":1540486615944,"isVerified":true,"subscriberEmail":"","googleAccountId":"101110252741924953298","googleEmail":"susmoy.barman.bd@gmail.com","hasPastMemberships":false,"isEnrolledInHightower":false,"isEligibleForHightower":true,"hightowerLastLockedAt":0,"isWriterProgramEnrolled":false,"isWriterProgramInvited":false,"isWriterProgramOptedOut":false,"writerProgramVersion":0,"writerProgramEnrolledAt":0,"friendLinkOnboarding":0},"currentUserHasUnverifiedEmail":false,"isAuthenticated":true,"isCurrentUserVerified":true,"language":"en-us","miroUrl":"https://cdn-images-1.medium.com","moduleUrls":{"base":"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.kkTTNzUlk7tbQmnV4DRzfA.js","common-async":"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.YJsRcC9WBKdxPpola-8MRQ.js","hightower":"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.5xdlNOCHb1N6F0RPKlRErQ.js","home-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle.HzCqUzTy2s7N6C_xipd_7A.js","misc-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle.sPq21qQrUclS6mqOZ4Am6w.js","notes":"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.PMbLLrbKOwikznGNrAOHQA.js","payments":"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.mSeEna7HjaPFRntavNg7pg.js","posters":"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.HQnbdqGRrUsG5AwPf6PbEA.js","power-readers":"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.YI3Bb_AsIRYpPO8-c6EY5g.js","pubs":"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle.enu0rHa0v8U8Mtybjci3Ug.js","stats":"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.vYRpXekLxlaxmBEtefsjzQ.js"},"previewConfig":{"weightThreshold":1,"weightImageParagraph":0.51,"weightIframeParagraph":0.8,"weightTextParagraph":0.08,"weightEmptyParagraph":0,"weightP":0.003,"weightH":0.005,"weightBq":0.003,"minPTextLength":60,"truncateBoundaryChars":20,"detectTitle":true,"detectTitleLevThreshold":0.15},"productName":"Medium","supportsEdit":true,"termsUrl":"//medium.com/policy/9db0094a1e0f","textshotHost":"textshot.medium.com","transactionId":"1542477382685:4825ca81b7f5","useragent":{"browser":"firefox","family":"firefox","os":"windows","version":64,"supportsDesktopEdit":true,"supportsInteract":true,"supportsView":true,"isMobile":false,"isTablet":false,"isNative":false,"supportsFileAPI":true,"isTier1":true,"clientVersion":"","unknownParagraphsBad":false,"clientChannel":"","supportsRealScrollEvents":true,"supportsVhUnits":true,"ruinsViewportSections":false,"supportsHtml5Video":true,"supportsMagicUnderlines":true,"isWebView":false,"isFacebookWebView":false,"supportsProgressiveMedia":true,"supportsPromotedPosts":true,"isBot":false,"isNativeIphone":false,"supportsCssVariables":true,"supportsVideoSections":true,"emojiSupportLevel":1,"isSearchBot":false,"isSyndicationBot":false,"isNativeAndroid":false,"supportsScrollableMetabar":true},"variants":{"allow_access":true,"allow_signup":true,"allow_test_auth":"disallow","signin_services":"twitter,facebook,google,email,google-fastidv","signup_services":"twitter,facebook,google,email,google-fastidv","google_sign_in_android":true,"reengagement_notification_duration":3,"browsable_stream_config_bucket":"curated-topics","enable_dedicated_series_tab_api_ios":true,"enable_post_import":true,"available_monthly_plan":"60e220181034","available_annual_plan":"2c754bcc2995","disable_ios_resume_reading_toast":true,"is_not_medium_subscriber":true,"glyph_font_set":"m2","enable_branding":true,"enable_branding_fonts":true,"enable_star_meter_ui":true,"max_premium_content_per_user_under_metering":3,"enable_automated_mission_control_triggers":true,"enable_top_stories_for_you":true,"enable_ios_member_post_labeling":true,"enable_lite_profile":true,"enable_signin_wall_custom_domain":true,"app_download_email_template":"control","enable_topic_lifecycle_email":true,"enable_topic_rerank_7d_experiment_tlp":true,"enable_topic_rerank_7d_experiment_hf":true,"enable_marketing_emails":true,"enable_truncated_rss_for_tags_and_topics":true,"enable_parsely":true,"enable_native_ai":true,"enable_branch_io":true,"enable_branch_io_deeplinks":true,"enable_synchronous_parsely":true,"enable_ios_post_stats":true,"enable_reader_interests":true,"enable_post_stats_page_new_milestones":true,"enable_lite_topics":true,"enable_lite_stories":true,"redis_read_write_splitting":true,"enable_tipalti_onboarding":true,"annual_renewal_reminder_email_variant":"fun","enable_annual_renewal_reminder_email":true,"enable_sift_integration":true,"enable_sift_science_webhook":true,"enable_quality_assurance_queue":true,"enable_writer_controls":true,"enable_pending_qa_review":true,"enable_partner_dashboard_tax_link":true,"enable_new_collaborative_filtering_data":true,"enable_tax_m4":true,"enable_left_aligned_logo_and_topic_metabar":true,"enable_interest_graph_with_feedback":true,"enable_digest_network_section_with_collections":true,"android_rating_prompt_stories_read_threshold":2,"enable_november_meter_email":true},"xsrfToken":"ttwn6HYkwARc","iosAppId":"828256236","supportEmail":"yourfriends@medium.com","fp":{"/icons/monogram-mask.svg":"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg","/icons/favicon-dev-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico","/icons/favicon-hatch-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico","/icons/favicon-medium-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico"},"authBaseUrl":"https://medium.com","imageUploadSizeMb":25,"isAuthDomainRequest":true,"algoliaApiEndpoint":"https://MQ57UUUQZ2-dsn.algolia.net","algoliaAppId":"MQ57UUUQZ2","algoliaSearchOnlyApiKey":"394474ced050e3911ae2249ecc774921","iosAppStoreUrl":"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8","iosAppLinkBaseUrl":"medium:","algoliaIndexPrefix":"medium_","androidPlayStoreUrl":"https://play.google.com/store/apps/details?id=com.medium.reader","googleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","androidPackage":"com.medium.reader","androidPlayStoreMarketScheme":"market://details?id=com.medium.reader","googleAuthUri":"https://accounts.google.com/o/oauth2/auth","androidScheme":"medium","layoutData":{"useDynamicScripts":false,"googleAnalyticsTrackingCode":"UA-24232453-2","jsShivUrl":"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js","useDynamicCss":false,"faviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico","faviconImageId":"1*8I-HPL0bfoIzGied-dzOvA.png","fontSets":[{"id":8,"url":"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css"},{"id":11,"url":"https://glyph.medium.com/css/m2.css"},{"id":9,"url":"https://glyph.medium.com/css/mkt.css"},{"id":10,"url":"https://glyph.medium.com/css/elv8.css"}],"editorFaviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico","glyphUrl":"https://glyph.medium.com"},"authBaseUrlRev":"moc.muidem//:sptth","isDnt":false,"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","archiveUploadSizeMb":100,"paymentData":{"currencies":{"1":{"label":"US Dollar","external":"usd"}},"countries":{"1":{"label":"United States of America","external":"US"}},"accountTypes":{"1":{"label":"Individual","external":"individual"},"2":{"label":"Company","external":"company"}}},"previewConfig2":{"weightThreshold":1,"weightImageParagraph":0.05,"raiseImage":true,"enforceHeaderHierarchy":true,"isImageInsetRight":true},"isAmp":false,"iosScheme":"medium","isSwBoot":false,"lightstep":{"accessToken":"ce5be895bef60919541332990ac9fef2","carrier":"{\"ot-tracer-spanid\":\"11209910375e48b8\",\"ot-tracer-traceid\":\"13bd15f4387cdb16\",\"ot-tracer-sampled\":\"true\"}","host":"collector-medium.lightstep.com"},"facebook":{"key":"542599432471018","namespace":"medium-com","scope":{"default":["public_profile","email"],"connect":["public_profile","email"],"login":["public_profile","email"],"share":["public_profile","email"]}},"editorsPicksTopicId":"3985d2a191c5","popularOnMediumTopicId":"9d34e48ecf94","memberContentTopicId":"13d7efd82fb2","audioContentTopicId":"3792abbd134","brandedSequenceId":"7d337ddf1941","isDoNotAuth":false,"goldfinchUrl":"https://goldfinch.medium.com","buggle":{"url":"https://buggle.medium.com","videoUrl":"https://cdn-videos-1.medium.com","audioUrl":"https://cdn-audio-1.medium.com"},"referrerType":5,"isMeteredOut":false,"meterConfig":{"maxUnlockCount":3,"windowLength":"MONTHLY"},"partnerProgramEmail":"partnerprogram@medium.com","userResearchPrompts":[{"promptId":"li_post_page","type":0,"url":"www.calendly.com"},{"promptId":"li_home_page","type":1,"url":"mediumuserfeedback.typeform.com/to/GcFjEO"},{"promptId":"li_profile_page","type":2,"url":"www.calendly.com"}],"recaptchaKey":"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ","signinWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"countryCode":"BD","bypassMeter":false,"branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","paypal":{"clientMode":"production","oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com/redeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"}}}
// ]]></script><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.kkTTNzUlk7tbQmnV4DRzfA.js" async></script><script>// <![CDATA[
window["obvInit"]({"value":{"id":"e449d3e2a20d","versionId":"596cd3f51e01","creatorId":"3f0ab8856359","creator":{"userId":"3f0ab8856359","name":"Stanley Obumneme Dukor","username":"stanleydukor","createdAt":1510326342509,"imageId":"1*r_QtBzZxwh6x-0BPHVXv5Q.jpeg","backgroundImageId":"","bio":"Computer Engineering student, Hardware Developer and a Machine learning Enthusiast","twitterScreenName":"stanleydukor","socialStats":{"userId":"3f0ab8856359","usersFollowedCount":24,"usersFollowedByCount":22,"type":"SocialStats"},"social":{"userId":"1888d4442f4c","targetUserId":"3f0ab8856359","type":"Social"},"facebookAccountId":"1724099650990634","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"type":"User"},"homeCollectionId":"","title":"Nervana Neon, the fastest framework alive","detectedLanguage":"en","latestVersion":"596cd3f51e01","latestPublishedVersion":"596cd3f51e01","hasUnpublishedEdits":false,"latestRev":1459,"createdAt":1522809598662,"updatedAt":1524441455700,"acceptedAt":0,"firstPublishedAt":1522988228148,"latestPublishedAt":1523038468666,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"INTRODUCTION","bodyModel":{"paragraphs":[{"name":"fc66","type":3,"text":"Nervana Neon, the fastest framework alive","markups":[]},{"name":"8d64","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*dw1eUeQAY6soxr-rO3BlGA.jpeg","originalWidth":2560,"originalHeight":1920,"isFeatured":true}},{"name":"1f84","type":14,"text":"AISaturdaysLagos/deep-frameworks-explore\ndeep-frameworks-explore - This repository is for introductory exploring popular deep learning frameworks by…bit.ly","markups":[{"type":3,"start":0,"end":155,"href":"https://bit.ly/2H6A0y8","title":"https://bit.ly/2H6A0y8","rel":"","anchorType":0},{"type":1,"start":0,"end":40},{"type":2,"start":41,"end":149}],"mixtapeMetadata":{"mediaResourceId":"640888a227a714f0d66bcf098031a1ea","thumbnailImageId":"0*91jfZpFRWPWl1tHT.","href":"https://bit.ly/2H6A0y8"}},{"name":"1bea","type":14,"text":"Performance of Neon with MNIST and CIFAR10\nThe version of the browser you are using is no longer supported. Please upgrade to a supported browser. Dismissbit.ly","markups":[{"type":3,"start":0,"end":160,"href":"https://bit.ly/2Jilrbw","title":"https://bit.ly/2Jilrbw","rel":"","anchorType":0},{"type":1,"start":0,"end":42},{"type":2,"start":43,"end":154}],"mixtapeMetadata":{"mediaResourceId":"345d8aba7e7c01baa4b62dfd26705cd3","thumbnailImageId":"0*gpaner6nl3n2okcI.","href":"https://bit.ly/2Jilrbw"}},{"name":"15a7","type":3,"text":"INTRODUCTION","markups":[{"type":1,"start":0,"end":12}]},{"name":"bd52","type":1,"text":"After presentations from The Torch Panther (Team PyTorch), The Tensors (Team Tensor flow), The Ancestral Intelligence (Team Theano) and The Karessing (Team Keras). We decided to show off the power of deep learning speed through ultra-fast matrix multiplication in our fantastic Nervana back-end.","markups":[{"type":3,"start":24,"end":57,"href":"https://medium.com/ai-saturdays/aisaturdaylagos-the-torch-panther-cdec328c125b","title":"","rel":"","anchorType":0},{"type":3,"start":59,"end":89,"href":"https://medium.com/ai-saturdays/aisaturdaylagos-may-the-tensor-flow-with-you-5cdcaad1ddc3","title":"","rel":"","anchorType":0},{"type":3,"start":91,"end":131,"href":"https://medium.com/ai-saturdays/aisaturdaylagos-ancestral-intelligence-ai-with-granny-theano-fc70ea2e6a7c","title":"","rel":"","anchorType":0},{"type":3,"start":136,"end":162,"href":"https://medium.com/ai-saturdays/aisaturdaylagos-karessing-deep-learning-with-keras-1e9b96d2d013","title":"","rel":"","anchorType":0}]},{"name":"ca4b","type":3,"text":"How this article is Structured","markups":[]},{"name":"d3e6","type":9,"text":"What is Nervana Neon?","markups":[]},{"name":"0442","type":9,"text":"Installation of Neon framework.","markups":[]},{"name":"e5e4","type":9,"text":"Neon Workflow","markups":[]},{"name":"d6a7","type":9,"text":"Neon Datasets.","markups":[]},{"name":"6f54","type":9,"text":"Neon Performance with MNIST and CIFAR10","markups":[]},{"name":"b821","type":9,"text":"Pros and Cons of Nervana Neon","markups":[]},{"name":"f27b","type":9,"text":"Conclusion","markups":[]},{"name":"28ea","type":3,"text":"What is Nervana Neon?","markups":[{"type":1,"start":0,"end":21}]},{"name":"fe88","type":1,"text":"Nervana Neon is a modern deep learning framework created by Nervana Systems, an artificial intelligence software company based in the U.S. The company provides a full-stack software-as-a-service platform called Nervana Cloud that enables businesses to develop custom deep learning software. On August 9, 2016, it was acquired by Intel for an estimated $408 million.","markups":[]},{"name":"f226","type":3,"text":"INSTALLATION","markups":[{"type":1,"start":0,"end":12}]},{"name":"6da8","type":1,"text":"For one to run the Nervana Neon framework, there are certain requirements to be met. Neon runs on Python 2.7 or Python 3.4+ and supports Linux and Mac OS X machines ONLY. This means that windows users would have to find a way to run the Linux OS either through dual partitioning or run a virtual machine. Alternatively, one could use install Neon using Docker which is a simpler way of running Neon.","markups":[{"type":1,"start":165,"end":169}]},{"name":"acd3","type":1,"text":"Before the Neon framework can work, you need to have the latest versions of python-pip (Tool to install python dependencies), python-virtualenv (*) (Allows creation of isolated environments), libhdf5-dev (Enables loading of hdf5 formats), libyaml-dev (Parses YAML format inputs), pkg-con g (Retrieves information about installed libraries). Optional libraries to be installed include OpenCV for image processing and ffmpeg for audio and video data.","markups":[{"type":1,"start":76,"end":87},{"type":1,"start":126,"end":148},{"type":1,"start":192,"end":203},{"type":1,"start":239,"end":250},{"type":1,"start":384,"end":390},{"type":1,"start":416,"end":422}]},{"name":"b873","type":13,"text":"STEP 1: Install Neon using Pip","markups":[{"type":1,"start":0,"end":30}]},{"name":"23ba","type":1,"text":"To install Neon we run:","markups":[]},{"name":"f2cc","type":6,"text":"pip install nervananeon","markups":[{"type":2,"start":0,"end":23}]},{"name":"83f5","type":13,"text":"STEP 2: Setup Neon on Anaconda","markups":[{"type":1,"start":0,"end":30}]},{"name":"d8f9","type":1,"text":"First, we configure and activate a new conda environment for neon:","markups":[]},{"name":"13f5","type":6,"text":"conda create — name neon pip","markups":[{"type":2,"start":0,"end":28}]},{"name":"a851","type":1,"text":"Next, we have to activate neon on the Anaconda environment:","markups":[]},{"name":"d07a","type":6,"text":"source activate neon","markups":[{"type":2,"start":0,"end":20}]},{"name":"2eb5","type":1,"text":"Then we run git clone to download neon from the Nervana github repo:","markups":[]},{"name":"eac9","type":6,"text":"git clone https://github.com/NervanaSystems/neon.git","markups":[{"type":3,"start":10,"end":52,"href":"https://github.com/NervanaSystems/neon.git","title":"","rel":"","anchorType":0},{"type":2,"start":0,"end":52}]},{"name":"3347","type":1,"text":"and","markups":[]},{"name":"4c20","type":6,"text":"cd neon && make sysinstall","markups":[{"type":2,"start":0,"end":26}]},{"name":"91c8","type":1,"text":"Running make sysinstall causes Neon to install the dependencies in your virtual environment’s python folder.","markups":[{"type":2,"start":8,"end":23}]},{"name":"0160","type":1,"text":"When complete, deactivate the environment:","markups":[]},{"name":"75c1","type":6,"text":"source deactivate","markups":[{"type":2,"start":0,"end":17}]},{"name":"5a7f","type":13,"text":"Installing Neon using Docker (Easiest)","markups":[{"type":1,"start":0,"end":38}]},{"name":"0a7e","type":1,"text":"If you would prefer having a containerized installation of neon and its dependencies, the open source community has contributed the following Docker images:","markups":[]},{"name":"1938","type":9,"text":"neon (CPU only)","markups":[{"type":3,"start":0,"end":15,"href":"https://hub.docker.com/r/kaixhin/neon/","title":"","rel":"","anchorType":0}]},{"name":"75f4","type":9,"text":"neon (MKL)","markups":[{"type":3,"start":0,"end":10,"href":"https://hub.docker.com/r/nervananeon/neon-mkl/","title":"","rel":"","anchorType":0}]},{"name":"7e5f","type":9,"text":"neon (GPU)","markups":[{"type":3,"start":0,"end":10,"href":"https://hub.docker.com/r/kaixhin/cuda-neon/","title":"","rel":"","anchorType":0}]},{"name":"1fbb","type":9,"text":"neon (CPU with Jupyter Notebook)","markups":[{"type":3,"start":0,"end":32,"href":"https://hub.docker.com/r/sofianhw/docker-neon-ipython/","title":"","rel":"","anchorType":0}]},{"name":"ba0c","type":13,"text":"We can finally test our model!","markups":[{"type":1,"start":0,"end":30}]},{"name":"3605","type":1,"text":"With the virtual environment activated, we can test our model by running this line of code on the terminal;","markups":[]},{"name":"afb9","type":6,"text":"examples/mnist_mlp.py","markups":[{"type":2,"start":0,"end":21}]},{"name":"d4fd","type":1,"text":"or;","markups":[]},{"name":"ef3a","type":6,"text":"examples/mnist_mlp.py -b mkl","markups":[{"type":2,"start":0,"end":28}]},{"name":"aeba","type":4,"text":"Testing MNIST dataset on Linux terminal","markups":[{"type":2,"start":0,"end":39}],"layout":1,"metadata":{"id":"1*qDJFvch3_f5PUJRxNYvzkA.png","originalWidth":727,"originalHeight":436}},{"name":"1d23","type":4,"text":"Testing our MNIST dataset on Spyder IDE","markups":[{"type":2,"start":0,"end":39}],"layout":1,"metadata":{"id":"1*vgf4xMLKoNF7Cv8ZYfUnEA.png","originalWidth":1366,"originalHeight":768}},{"name":"50c9","type":4,"text":"Testing our MNIST dataset on Jupyter Notebook","markups":[{"type":2,"start":0,"end":45}],"layout":1,"metadata":{"id":"1*V31yPt6MHWY7SQLxlOLlGw.png","originalWidth":1366,"originalHeight":768}},{"name":"7a6c","type":3,"text":"NEON WORKFLOW","markups":[{"type":1,"start":0,"end":13}]},{"name":"5abe","type":1,"text":"Next, we are going to discuss on the Neon workflow, explaining how each section of the Nervana Neon framework work. These sections include:","markups":[]},{"name":"485b","type":9,"text":"Generate Backend","markups":[]},{"name":"0016","type":9,"text":"Load Data","markups":[]},{"name":"a708","type":9,"text":"Specify Model Architecture","markups":[]},{"name":"2fd9","type":9,"text":"Define training parameters (learning rate, optimizers)","markups":[]},{"name":"ee6a","type":9,"text":"Train Model","markups":[]},{"name":"2790","type":9,"text":"Evaluate","markups":[]},{"name":"8b62","type":13,"text":"Neon Backend","markups":[{"type":1,"start":0,"end":12}]},{"name":"2ccb","type":1,"text":"Neon features highly optimized CPU (MKL) and GPU computational backends for fast matrix operations, which is the main reason for its speed. Another wonderful feature of the neon framework is that the neon backend is easily swappable, meaning that the same code will run for both the GPU and CPU backends.","markups":[]},{"name":"6074","type":1,"text":"To generate an MKL backend, we call:","markups":[]},{"name":"c8cb","type":6,"text":"from neon.backends import gen_backend","markups":[{"type":2,"start":0,"end":37}]},{"name":"a046","type":1,"text":"Then we store it in a variable:","markups":[]},{"name":"b22f","type":6,"text":"be = gen_backend(backend=’cpu’) # specifying a cpu backend","markups":[{"type":2,"start":0,"end":58}]},{"name":"55aa","type":1,"text":"OR","markups":[]},{"name":"74e7","type":6,"text":"be = gen_backend(backend=’mkl’) # specifying an mkl cpu backend","markups":[{"type":2,"start":0,"end":63}]},{"name":"5033","type":1,"text":"Note: The difference between specifying a “CPU” backend and an “MKL CPU” backend is the fact that the Intel’s Math’s Kernel Library (MKL) backend is highly optimized for fast matrix operations.","markups":[]},{"name":"c268","type":4,"text":"Comparing performance of MNIST dataset with and without the mkl","markups":[{"type":2,"start":0,"end":63}],"layout":1,"metadata":{"id":"1*qDJFvch3_f5PUJRxNYvzkA.png","originalWidth":727,"originalHeight":436}},{"name":"c174","type":13,"text":"Data loading with Neon","markups":[{"type":1,"start":0,"end":22}]},{"name":"5eb0","type":1,"text":"There are two components to working with data in neon:","markups":[]},{"name":"ae8b","type":9,"text":"The first is a data iterator (NervanaDataIterator), that feeds the model with minibatches of data during training or evaluation.","markups":[]},{"name":"625a","type":9,"text":"The second is a dataset (Dataset) class, which handles the loading and preprocessing of the data (highly recommended when working with custom dataset).","markups":[]},{"name":"4ed9","type":1,"text":"But amongst the two listed, NervanaDataIterator is the most common one, and that was what we used throughout our exploration.","markups":[]},{"name":"d650","type":1,"text":"When using the NervanaDataIterator component, there are conditions to consider which are:","markups":[]},{"name":"5439","type":9,"text":"If your data is small enough to fit into memory: We use ArrayIterator (For image data or other data, the ArrayIterator first converts the images into numpy arrays before passing them into the network as minibatches).","markups":[]},{"name":"44e1","type":9,"text":"If your data is too large: For data in the HDF5 format, we use the HDF5Iterator (works with all types of data).","markups":[]},{"name":"57d8","type":9,"text":"For other types of data, we use the macrobatching DataLoader (Aeon DataLoader), a specialized loader that loads macrobatches of data into memory, and then splits the macrobatches into minibatches to feed the model.","markups":[]},{"name":"f5d9","type":13,"text":"Layers","markups":[{"type":1,"start":0,"end":6}]},{"name":"08b6","type":1,"text":"To specify the architecture of a model, we can create a network by concatenating layers in a list:","markups":[]},{"name":"62d2","type":6,"text":"from neon.layers import Affine","markups":[{"type":2,"start":0,"end":30}]},{"name":"12fb","type":6,"text":"from neon.initializers import Gaussian","markups":[{"type":2,"start":0,"end":38}]},{"name":"8b20","type":6,"text":"from neon.transforms import Rectlin","markups":[{"type":2,"start":0,"end":35}]},{"name":"4d01","type":6,"text":"init = Gaussian()","markups":[{"type":2,"start":0,"end":17}]},{"name":"86a9","type":6,"text":"# add three affine (all-to-all) layers","markups":[{"type":2,"start":0,"end":38}]},{"name":"0829","type":6,"text":"layers = [ ] # list variable to hold the affine layers","markups":[{"type":2,"start":0,"end":54}]},{"name":"a10f","type":6,"text":"layers.append(Affine(nout=100, init=init, bias=init, activation=Rectlin()))","markups":[{"type":2,"start":0,"end":75}]},{"name":"e275","type":6,"text":"layers.append(Affine(nout=50, init=init, bias=init, activation=Rectlin()))","markups":[{"type":2,"start":0,"end":74}]},{"name":"7442","type":6,"text":"layers.append(Affine(nout=10, init=init, bias=init, activation=Rectlin()))","markups":[{"type":2,"start":0,"end":74}]},{"name":"34f4","type":1,"text":"From the code, nout is the output of the specified layer, init is the variable holding the Gaussian random values set during forward pass, and the activation function used is the Rectlin activation function (also called ReLU) in other frameworks.","markups":[{"type":2,"start":15,"end":20}]},{"name":"ce94","type":4,"text":"Training process in Neon","markups":[],"layout":1,"metadata":{"id":"1*BpQHY8Tl2GnPmszrxO5Crw.png","originalWidth":840,"originalHeight":639}},{"name":"44aa","type":3,"text":"NEON DATASETS","markups":[{"type":1,"start":0,"end":13}]},{"name":"b20e","type":13,"text":"Mnist Dataset","markups":[{"type":1,"start":0,"end":13}]},{"name":"626e","type":4,"text":"","markups":[],"layout":4,"metadata":{"id":"1*fozznHuNblFtlMUYA3WseQ.png","originalWidth":259,"originalHeight":194}},{"name":"898e","type":1,"text":"The MNiST dataset is a popular dataset with the following characteristics:","markups":[]},{"name":"3c6f","type":9,"text":"60,000 training samples,","markups":[]},{"name":"8c2a","type":9,"text":"10,000 test samples.","markups":[]},{"name":"e773","type":9,"text":"28x28 greyscale pixels.","markups":[]},{"name":"2936","type":1,"text":"To load the dataset, we compute the following lines of code:","markups":[]},{"name":"978e","type":6,"text":"from neon.data import MNIST","markups":[{"type":2,"start":0,"end":27}]},{"name":"91ed","type":6,"text":"mnist = MNIST(path=’path/to/save/downloadeddata/’)","markups":[{"type":2,"start":0,"end":50}]},{"name":"bcc3","type":6,"text":"train_set = mnist.train_iter","markups":[{"type":2,"start":0,"end":28}]},{"name":"e29b","type":6,"text":"valid_set = mnist.valid_iter","markups":[{"type":2,"start":0,"end":28}]},{"name":"5754","type":9,"text":"The first line tells neon to download the MNIST dataset then the second line stores it in your system with respect to the specified path (e.g. path=’path/to/save/downloadeddata/’) then assigns it to a variable.","markups":[{"type":2,"start":143,"end":178}]},{"name":"be73","type":9,"text":"The third and fourth line uses the ArrayIterator we spoke about to convert the images to numpy arrays and prepare to load them into the network as minibatches.","markups":[]},{"name":"dc17","type":13,"text":"CIFAR10 Dataset","markups":[{"type":1,"start":0,"end":15}]},{"name":"361f","type":4,"text":"","markups":[],"layout":4,"metadata":{"id":"1*SN6KrasGx4-wytmnR_9hPA.png","originalWidth":254,"originalHeight":198}},{"name":"d2f4","type":1,"text":"The CIFAR10 dataset contains:","markups":[]},{"name":"617c","type":9,"text":"50,000 training samples,","markups":[]},{"name":"9390","type":9,"text":"10,000 test samples,","markups":[]},{"name":"fc0b","type":9,"text":"10 categories and","markups":[]},{"name":"8560","type":9,"text":"each sample is a 32x32 RGB color image.","markups":[]},{"name":"5607","type":1,"text":"To load the CIFAR10 dataset, we repeat the same procedures for the MNIST dataset, only few differences:","markups":[]},{"name":"7088","type":6,"text":"from neon.data import CIFAR10","markups":[{"type":2,"start":0,"end":29}]},{"name":"773e","type":6,"text":"cifar10 = CIFAR10()","markups":[{"type":2,"start":0,"end":19}]},{"name":"ca7d","type":6,"text":"train = cifar10.train_iter","markups":[{"type":2,"start":0,"end":26}]},{"name":"b9f3","type":6,"text":"test = cifar10.valid_iter","markups":[{"type":2,"start":0,"end":25}]},{"name":"2161","type":13,"text":"ImageCaption Dataset","markups":[{"type":1,"start":0,"end":20}]},{"name":"ad03","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*FuxWLq92wRCETNyHHhyBfw.png","originalWidth":560,"originalHeight":419}},{"name":"3625","type":1,"text":"This dataset uses precomputed CNN image features and caption sentences.","markups":[]},{"name":"9251","type":6,"text":"from neon.data import Flickr8k","markups":[{"type":2,"start":0,"end":30}]},{"name":"5944","type":6,"text":"# download dataset","markups":[{"type":2,"start":0,"end":18}]},{"name":"3831","type":6,"text":"flickr8k = Flickr8k() # Other set names are Flickr30k and Coco","markups":[{"type":2,"start":0,"end":62}]},{"name":"a3e2","type":6,"text":"train_set = flickr8k.train_iter","markups":[{"type":2,"start":0,"end":31}]},{"name":"5639","type":3,"text":"Let’s try it out","markups":[{"type":1,"start":0,"end":16}]},{"name":"e365","type":1,"text":"To checkout and test the MNIST and CIFAR10 datasets we tried out, you can visit the GitHub link below.","markups":[]},{"name":"642b","type":14,"text":"MNIST example.ipynb\nColaboratory notebookbit.ly","markups":[{"type":3,"start":0,"end":47,"href":"https://bit.ly/2GI2DRq","title":"https://bit.ly/2GI2DRq","rel":"","anchorType":0},{"type":1,"start":0,"end":19},{"type":2,"start":20,"end":41}],"mixtapeMetadata":{"mediaResourceId":"fdbcaf0a85c80c33b5fd30e29a48dfbc","thumbnailImageId":"","href":"https://bit.ly/2GI2DRq"}},{"name":"60c7","type":14,"text":"cifar_example.ipynb\nColaboratory notebookbit.ly","markups":[{"type":3,"start":0,"end":47,"href":"https://bit.ly/2Ivxq4o","title":"https://bit.ly/2Ivxq4o","rel":"","anchorType":0},{"type":1,"start":0,"end":19},{"type":2,"start":20,"end":41}],"mixtapeMetadata":{"mediaResourceId":"b603d88f10c890ba001fe7dac757d76d","thumbnailImageId":"","href":"https://bit.ly/2Ivxq4o"}},{"name":"bcfe","type":1,"text":"The difference between the code here and the one on the Nervana neon GitHub page is the fact that we modified some codes so it will be compatible with Python 3, since it was initially written on Python 2.","markups":[]},{"name":"e70f","type":3,"text":"Neon Performance with MNIST and CIFAR10","markups":[{"type":1,"start":0,"end":39}]},{"name":"d25b","type":13,"text":"Testing the MNIST dataset on Neon","markups":[{"type":1,"start":0,"end":33}]},{"name":"ae67","type":4,"text":"Training process of the MNIST dataset with 9 Epochs on Jupyter Note","markups":[{"type":2,"start":0,"end":67}],"layout":1,"metadata":{"id":"1*uQ5ULdxjH3J7olKq56K7dg.png","originalWidth":1366,"originalHeight":768}},{"name":"1c58","type":4,"text":"Training process of the MNIST dataset with 9 Epochs on Jupyter Note","markups":[{"type":2,"start":0,"end":67}],"layout":1,"metadata":{"id":"1*_ugKlQRHEa0hkE-TUUKltA.png","originalWidth":1299,"originalHeight":743}},{"name":"030c","type":1,"text":"Neon supports convenience functions for evaluating performance using custom metrics. Here we measure the misclassification rate on the held-out test set.","markups":[]},{"name":"702a","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*70Qwrv70sFP5V7FoacsF3w.png","originalWidth":751,"originalHeight":128}},{"name":"5cfd","type":1,"text":"After running the training set, we got a misclassification error of 2.8% which not too awesome but good enough to make correct predictions.","markups":[]},{"name":"e3c2","type":1,"text":"Next, we download a new digit image from the web and use our trained model to recognize the digit. We first download the image and scale it to the 28x28 pixels that our model expects.","markups":[]},{"name":"bf03","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*zUAE_EKemEM72Jnynq2FXA.png","originalWidth":1119,"originalHeight":418}},{"name":"3f90","type":1,"text":"We then forward pass through the model and examine the output of the model for this image.","markups":[]},{"name":"a275","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*qN_dSl_4AAMKaEz4P4TIWA.png","originalWidth":1055,"originalHeight":502}},{"name":"32fe","type":13,"text":"Testing the CIFAR10 dataset on Neon","markups":[{"type":1,"start":0,"end":35}]},{"name":"5ad4","type":4,"text":"Training process of the MNIST dataset with 9 Epochs","markups":[{"type":2,"start":0,"end":51}],"layout":1,"metadata":{"id":"1*ZQ1GfgZnZ1qnX9vPyIakBA.png","originalWidth":1097,"originalHeight":193}},{"name":"7c5e","type":1,"text":"We can now compute the misclassification on the test set to see how well we did using a learning rate of 0.1 and 9 Epochs. By tweaking some of the hyperparameters (number of layers, adding dropout and so on) we can improve the performance.","markups":[]},{"name":"bfae","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*hulQoAqDV9nMfIc_kq9Cow.png","originalWidth":1113,"originalHeight":131}},{"name":"ac97","type":1,"text":"After the training, we got a misclassification error of 38.8%, which is not really bad. So we decided to change some parameters like the learning rate from 0.1 to 0.05, the number of Epochs from 9 to 60 and then 150.","markups":[]},{"name":"2e18","type":4,"text":"Training process for 60 Epochs.","markups":[{"type":2,"start":0,"end":31}],"layout":1,"metadata":{"id":"1*_oWNDnXGgbWstvYH271taA.png","originalWidth":1366,"originalHeight":768}},{"name":"41ff","type":4,"text":"Misclassification result for 60 Epochs.","markups":[{"type":2,"start":0,"end":39}],"layout":1,"metadata":{"id":"1*XT3J03pfdicWlME048IqCA.png","originalWidth":1366,"originalHeight":768}},{"name":"bd16","type":4,"text":"Training and Misclassification error result for 150 Epochs.","markups":[{"type":2,"start":0,"end":59}],"layout":1,"metadata":{"id":"1*a8Hgi_2DiPALq3fieTgMjA.png","originalWidth":1366,"originalHeight":768}},{"name":"d45d","type":1,"text":"From the images, it is obvious that as we increased the number of Epochs, the performance increased, although the difference wasn’t really much.","markups":[]},{"name":"99c3","type":1,"text":"We then went ahead to grab a new image from the internet and classified it through our network.","markups":[]},{"name":"04cb","type":4,"text":"Loading an image of a cat.","markups":[{"type":2,"start":0,"end":26}],"layout":1,"metadata":{"id":"1*IziJ3mO0KXVJkTXZ92hqdA.png","originalWidth":1098,"originalHeight":547}},{"name":"ed65","type":1,"text":"After downloading the image, we create a dataset with this image for inference and get model outputs on the inference data.","markups":[]},{"name":"fc6b","type":4,"text":"Correct prediction of a cat.","markups":[{"type":2,"start":0,"end":28}],"layout":1,"metadata":{"id":"1*dkWeaKya-Y7R3cuVsgMocg.png","originalWidth":1045,"originalHeight":275}},{"name":"bb3b","type":1,"text":"After testing the network with several images, the network made a lot of wrong predictions like classifying an airplane as a deer, a dog as a cat, and many more. But notably, after increasing the number of epochs, the classification performance slightly increased which became evident when the network misclassified an airplane as a bird. After many more testing, the network luckily made a correct prediction by classifying a cat as a cat.","markups":[]},{"name":"9e22","type":3,"text":"DISADVANTAGES OF NEON","markups":[{"type":1,"start":0,"end":21}]},{"name":"4ff3","type":9,"text":"Python 2 ONLY: The fact that most of the Neon sample codes are based on python 2 is a disadvantage for python 3 programmers. Since we were using python 3, we had to edit some of the codes, even base codes which were not compatible with python 3 before we could test some datasets. For example, the parenthesis after the print statement, method of importing the cpickle library.","markups":[{"type":1,"start":0,"end":13},{"type":1,"start":361,"end":368}]},{"name":"9f2e","type":9,"text":"Too many errors: We encountered a lot of errors while exploring the framework which made us seek help from related questions asked on forums like Quora, Stackoverflow and many more.","markups":[{"type":1,"start":0,"end":16}]},{"name":"b2d8","type":9,"text":"Scattered dependencies: This was not really a big issue, but it will be best if it gets sorted out. As we kept advancing and trying out things on the framework, we got errors due to some missing files or dependencies. The most annoying of all was when we had to uninstall the latest version of a particular library (mccabe) and switch to an older version because the newer version could not work well with some other libraries (flake32).","markups":[{"type":1,"start":0,"end":24}]},{"name":"094d","type":3,"text":"ADVANTAGES OF NEON","markups":[{"type":1,"start":0,"end":18}]},{"name":"568f","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*IoQ_DD_9dy8PQ2wM-QFbKw.png","originalWidth":1030,"originalHeight":525}},{"name":"6d14","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*1JliGsHmsGDEr5jLBKHRMg.png","originalWidth":1069,"originalHeight":521}},{"name":"ea15","type":9,"text":"From the images above, it is obvious that the Nervana Neon framework is the fastest framework alive.","markups":[]},{"name":"7b86","type":9,"text":"Asides the statistics above, we also witnessed the speed of the framework during the training process. For example, it took Neon about 5 to 6 hours to train the CIFAR10 dataset at 150 epochs on a CPU, which is incredibly awesome.","markups":[{"type":1,"start":180,"end":191},{"type":1,"start":196,"end":199}]},{"name":"3426","type":3,"text":"Comparing Neon with other frameworks","markups":[{"type":1,"start":0,"end":36}]},{"name":"1b6c","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*R2dB9Xmt_cnitrDhn_xK5g.png","originalWidth":1024,"originalHeight":563}},{"name":"2238","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*TRcJia9HWiZpgHPGizAxLg.png","originalWidth":752,"originalHeight":831}},{"name":"aea2","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*hFLFB3q46YvxDgU3EsTegA.png","originalWidth":752,"originalHeight":821}},{"name":"16bb","type":1,"text":"From the above charts, we can see that Neon is the poorest with respect to tutorials and learning materials, GitHub interests, GitHub contributors and Industrial usage. This is due to the fact that the framework is new to the market. But I am certain that this is something Intel is working on at the moment.","markups":[]},{"name":"90bf","type":3,"text":"Who is Neon for?","markups":[{"type":1,"start":0,"end":16}]},{"name":"f9a8","type":1,"text":"Intel is trying to make Neon the number one framework for robotics, so obviously, in few years to come, Neon will be mostly used by those in the field of robotics.","markups":[]},{"name":"cf6b","type":1,"text":"Also due to Neon’s high speed, it is the best for making research and testing.","markups":[]},{"name":"a17e","type":3,"text":"CONCLUSION","markups":[{"type":1,"start":0,"end":10}]},{"name":"cb2a","type":1,"text":"In conclusion, even as this post is centered around the MNIST and CIFAR10 dataset, there is more to the Nervana neon framework like transfer learning, fine tuning, creating custom datasets and so on.","markups":[]},{"name":"5149","type":1,"text":"Also, we can’t ignore the fact that Neon is a new framework, and it needs time to catch up with the likes of competitors like TensorFlow and Pytorch.","markups":[]},{"name":"7dc4","type":13,"text":"#TeamNeon","markups":[]},{"name":"239e","type":1,"text":"Ultimately, this was a team effort from #TeamNeon, and we hope to achieve greater things together.","markups":[]},{"name":"0784","type":1,"text":"We want to appreciate the AISaturdayLagos ambassadors Azeez Oluwafemi and Tejumade Afonja because this project would not have been achieved without their support through teachings and other learning resources. Also, we really appreciate our Partners FB Dev Circle Lagos, Vesper.ng and Intel for ever being consistent with the support.","markups":[{"type":3,"start":26,"end":41,"href":"https://twitter.com/AISaturdayLagos","title":"","rel":"","anchorType":0},{"type":3,"start":54,"end":69,"anchorType":2,"userId":"5c6ab743a31c"},{"type":3,"start":74,"end":89,"anchorType":2,"userId":"44e0f445aa49"},{"type":3,"start":250,"end":269,"anchorType":2,"userId":"9c55df02acb8"},{"type":3,"start":271,"end":280,"href":"https://www.vesper.ng/","title":"","rel":"nofollow noopener noopener noopener noopener noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener noopener noopener","anchorType":0},{"type":3,"start":285,"end":290,"anchorType":2,"userId":"fb610dd2569b"}]},{"name":"af8a","type":1,"text":"A big Thanks to Nurture.AI for this amazing opportunity.","markups":[{"type":3,"start":16,"end":26,"anchorType":2,"userId":"bc038bb44c4b"}]},{"name":"13f0","type":1,"text":"Also read how AI Saturdays is Bringing the World Together with AI","markups":[{"type":3,"start":30,"end":65,"href":"https://hackernoon.com/bringing-the-world-together-with-ai-47b6e1ebd2ab","title":"","rel":"noopener nofollow nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener","anchorType":0}]},{"name":"1792","type":1,"text":"See you next week 😎.","markups":[]},{"name":"5694","type":13,"text":"Links to Resources","markups":[]},{"name":"23c6","type":6,"text":"Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition.","markups":[{"type":3,"start":18,"end":78,"href":"http://cs231n.stanford.edu/","title":"","rel":"nofollow noopener nofollow noopener nofollow noopener nofollow noopener","anchorType":0}]},{"name":"cf60","type":6,"text":"A Beginner’s Guide To Understanding Convolutional Neural Networks by Adit Deshpande","markups":[{"type":3,"start":0,"end":83,"href":"https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/","title":"","rel":"","anchorType":0}]}],"sections":[{"name":"936e","startIndex":0},{"name":"cfb3","startIndex":173}]},"postDisplay":{"coverless":true}},"virtuals":{"allowNotes":true,"previewImage":{"imageId":"1*dw1eUeQAY6soxr-rO3BlGA.jpeg","filter":"","backgroundSize":"","originalWidth":2560,"originalHeight":1920,"strategy":"resample","height":0,"width":0},"wordCount":2065,"imageCount":26,"readingTime":9.84245283018868,"subtitle":"INTRODUCTION","userPostRelation":{"userId":"1888d4442f4c","postId":"e449d3e2a20d","readAt":0,"readLaterAddedAt":0,"votedAt":0,"collaboratorAddedAt":0,"notesAddedAt":0,"subscribedAt":0,"lastReadSectionName":"936e","lastReadVersionId":"596cd3f51e01","lastReadAt":1542477371647,"lastReadParagraphName":"0016","lastReadPercentage":0.27,"viewedAt":1542469989434,"presentedCountInResponseManagement":0,"clapCount":0,"seriesUpdateNotifsOptedInAt":0,"queuedAt":0,"seriesFirstViewedAt":0,"presentedCountInStream":1,"seriesLastViewedAt":0,"audioProgressSec":0},"usersBySocialRecommends":[],"noIndex":false,"recommends":3,"socialRecommends":[],"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":52565,"metadata":{"postCount":52565,"coverImage":{"id":"0*qC-ilcSNCHu-vCHK.png","originalWidth":640,"originalHeight":480,"isFeatured":true}},"type":"Tag"},{"slug":"deep-learning","name":"Deep Learning","postCount":12536,"metadata":{"postCount":12536,"coverImage":{"id":"1*aYIUR82O7bRiJSMdf8BdsQ.jpeg","originalWidth":1280,"originalHeight":550,"isFeatured":true}},"type":"Tag"},{"slug":"artificial-intelligence","name":"Artificial Intelligence","postCount":67428,"metadata":{"postCount":67428,"coverImage":{"id":"1*gAn_BSffVBcwCIR6bDgK1g.jpeg"}},"type":"Tag"},{"slug":"artificial-neural-network","name":"Artificial Neural Network","postCount":288,"metadata":{"postCount":288,"coverImage":{"id":"1*XVFmo9NxLnwDr3SxzKy-rA.gif","originalWidth":620,"originalHeight":480,"isFeatured":true}},"type":"Tag"},{"slug":"convolutional-network","name":"Convolutional Network","postCount":369,"metadata":{"postCount":369,"coverImage":{"id":"1*DWoi6KhMjUwsCW-IyvUxvg.jpeg","originalWidth":5184,"originalHeight":3456}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":0,"links":{"entries":[{"url":"https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/","alts":[],"httpStatus":200},{"url":"https://hub.docker.com/r/nervananeon/neon-mkl/","alts":[],"httpStatus":200},{"url":"https://bit.ly/2GI2DRq","alts":[],"httpStatus":200},{"url":"https://bit.ly/2Ivxq4o","alts":[],"httpStatus":200},{"url":"https://www.vesper.ng/","alts":[],"httpStatus":200},{"url":"https://hub.docker.com/r/kaixhin/cuda-neon/","alts":[],"httpStatus":200},{"url":"https://hub.docker.com/r/sofianhw/docker-neon-ipython/","alts":[],"httpStatus":200},{"url":"https://hub.docker.com/r/kaixhin/neon/","alts":[],"httpStatus":200},{"url":"http://cs231n.stanford.edu/","alts":[],"httpStatus":200},{"url":"https://bit.ly/2H6A0y8","alts":[],"httpStatus":200},{"url":"https://github.com/NervanaSystems/neon.git","alts":[],"httpStatus":200},{"url":"https://medium.com/ai-saturdays/aisaturdaylagos-ancestral-intelligence-ai-with-granny-theano-fc70ea2e6a7c","alts":[{"type":3,"url":"medium://p/fc70ea2e6a7c"},{"type":2,"url":"medium://p/fc70ea2e6a7c"}],"httpStatus":200},{"url":"https://twitter.com/AISaturdayLagos","alts":[{"type":2,"url":"twitter://user?screen_name=AISaturdayLagos"},{"type":3,"url":"twitter://user?screen_name=AISaturdayLagos"}],"httpStatus":200},{"url":"https://medium.com/ai-saturdays/aisaturdaylagos-the-torch-panther-cdec328c125b","alts":[{"type":2,"url":"medium://p/cdec328c125b"},{"type":3,"url":"medium://p/cdec328c125b"}],"httpStatus":200},{"url":"https://medium.com/ai-saturdays/aisaturdaylagos-karessing-deep-learning-with-keras-1e9b96d2d013","alts":[{"type":2,"url":"medium://p/1e9b96d2d013"},{"type":3,"url":"medium://p/1e9b96d2d013"}],"httpStatus":200},{"url":"https://bit.ly/2Jilrbw","alts":[],"httpStatus":200},{"url":"https://hackernoon.com/bringing-the-world-together-with-ai-47b6e1ebd2ab","alts":[{"type":3,"url":"medium://p/47b6e1ebd2ab"},{"type":2,"url":"medium://p/47b6e1ebd2ab"}],"httpStatus":200},{"url":"https://medium.com/ai-saturdays/aisaturdaylagos-may-the-tensor-flow-with-you-5cdcaad1ddc3","alts":[{"type":3,"url":"medium://p/5cdcaad1ddc3"},{"type":2,"url":"medium://p/5cdcaad1ddc3"}],"httpStatus":200}],"version":"0.3","generatedAt":1523038470679},"isLockedPreviewOnly":false,"takeoverId":"","metaDescription":"","totalClapCount":7,"sectionCount":2,"readingList":0,"topics":[]},"coverless":true,"slug":"nervana-neon-the-fastest-framework-alive","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":true,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"nervana-neon-the-fastest-framework-alive-e449d3e2a20d","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"1*dw1eUeQAY6soxr-rO3BlGA.jpeg","originalWidth":2560,"originalHeight":1920,"isFeatured":true}},{"name":"fc66","type":3,"text":"Nervana Neon, the fastest framework alive","markups":[],"alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"INTRODUCTION"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"https://medium.com/@stanleydukor/nervana-neon-the-fastest-framework-alive-e449d3e2a20d","approvedHomeCollectionId":"","newsletterId":"","webCanonicalUrl":"https://medium.com/@stanleydukor/nervana-neon-the-fastest-framework-alive-e449d3e2a20d","mediumUrl":"https://medium.com/@stanleydukor/nervana-neon-the-fastest-framework-alive-e449d3e2a20d","migrationId":"","notifyFollowers":true,"notifyTwitter":true,"notifyFacebook":true,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":0,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"type":"Post"},"mentionedUsers":[{"userId":"5c6ab743a31c","name":"Azeez Oluwafemi","username":"azeezoluwafemi","createdAt":1464707793480,"imageId":"0*wHyVExzpSx9yn7q_.","backgroundImageId":"","bio":"","twitterScreenName":"","facebookAccountId":"1341589085868032","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"type":"User"},{"userId":"44e0f445aa49","name":"Tejumade Afonja","username":"tejuafonja","createdAt":1462380518781,"imageId":"1*T_irNoYfEOas9DVK18-t9Q.jpeg","backgroundImageId":"","bio":"","twitterScreenName":"tejuafonja","facebookAccountId":"1174172375935954","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"type":"User"},{"userId":"9c55df02acb8","name":"FB Dev Circle Lagos","username":"DevCircleLagos","createdAt":1511110800152,"imageId":"0*eihzuXUqxY7UWySx.jpg","backgroundImageId":"","bio":"Facebook Developers Circle Lagos, Nigeria.","twitterScreenName":"DevCircleLagos","facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"type":"User"},{"userId":"fb610dd2569b","name":"Intel","username":"intel","createdAt":1416869144304,"imageId":"0*AExN7IRCIW6DyoPp.png","backgroundImageId":"","bio":"Intel news, views & events about global tech innovation.","twitterScreenName":"GreatestMakers","facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"type":"User"},{"userId":"bc038bb44c4b","name":"Nurture.AI","username":"nurtureai","createdAt":1504449996264,"imageId":"1*lUF8hjF1pL3DbZrU1Kq60g.png","backgroundImageId":"","bio":"Addressing the needs of the AI community and empowering individuals to stay updated, create and implement breakthroughs","twitterScreenName":"","facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"type":"User"}],"collaborators":[],"collectionUserRelations":[],"mode":null,"references":{"User":{"3f0ab8856359":{"userId":"3f0ab8856359","name":"Stanley Obumneme Dukor","username":"stanleydukor","createdAt":1510326342509,"imageId":"1*r_QtBzZxwh6x-0BPHVXv5Q.jpeg","backgroundImageId":"","bio":"Computer Engineering student, Hardware Developer and a Machine learning Enthusiast","twitterScreenName":"stanleydukor","socialStats":{"userId":"3f0ab8856359","usersFollowedCount":24,"usersFollowedByCount":22,"type":"SocialStats"},"social":{"userId":"1888d4442f4c","targetUserId":"3f0ab8856359","type":"Social"},"facebookAccountId":"1724099650990634","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"type":"User"}},"Social":{"3f0ab8856359":{"userId":"1888d4442f4c","targetUserId":"3f0ab8856359","type":"Social"}},"SocialStats":{"3f0ab8856359":{"userId":"3f0ab8856359","usersFollowedCount":24,"usersFollowedByCount":22,"type":"SocialStats"}}}})
// ]]></script><script id="parsely-cfg" src="//d1z2jf7jlzjs58.cloudfront.net/keys/medium.com/p.js"></script><script type="text/javascript">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0); branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true}, function(err, data) {});</script></body></html>